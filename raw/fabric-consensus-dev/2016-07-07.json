[
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yey, getting close",
        "ts": "1467901498.001557"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "panic in sign: not implemented",
        "ts": "1467901507.001558"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "this is where i don't know what to do",
        "ts": "1467901520.001559"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "the crypto layer in fabric is huge and confusing",
        "ts": "1467901536.001560"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Yes, I know there are the assorted certificate types, but it seems like we may have to introduce new ones for the consenter\/endorser split?",
        "ts": "1467901584.001561"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "hmm",
        "ts": "1467901732.001562"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "messages not being broadcast?",
        "ts": "1467901736.001563"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so, we never start our outstanding requests timer when there are outstanding requests",
        "ts": "1467901792.001564"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "but we also don't submit them",
        "ts": "1467901797.001565"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "should we?",
        "ts": "1467901803.001566"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "why is the consensus code still using vp0... etc?",
        "ts": "1467901946.001567"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "instead of actual peerids?",
        "ts": "1467901952.001568"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "what a mess this is",
        "ts": "1467901956.001569"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The outstanding request stuff is definitely pending an overhaul, it is a mess",
        "ts": "1467902210.001570"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I've got some outstanding code to fix this",
        "ts": "1467902217.001571"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "But, I'm waiting for <@U0XQ35CDD> to finish with his work to make the PrePrepare carry a non-opaque RequestBlock instead of a Request, so that we can then merge core\/batch",
        "ts": "1467902282.001572"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "And I'm not sure what you mean by \"vp0...\" etc.? I see that some in our tests, and, we need to keep a ReplicaID around, so that we can compute the leader after viewchange (for which a peerID wouldn't suffice)",
        "ts": "1467902363.001573"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "well the interface sucks",
        "ts": "1467902587.001574"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "we require the peerid to match vp%d",
        "ts": "1467902600.001575"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "which is pointless",
        "ts": "1467902607.001576"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Oh, I thought we killed that",
        "ts": "1467902609.001577"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yea so did i",
        "ts": "1467902613.001578"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I thought we have behave tests which verify this",
        "ts": "1467902627.001579"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i wrote code for a whitelist with certificates",
        "ts": "1467902648.001580"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "but it doesn't live inside pbft",
        "ts": "1467902658.001581"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "maybe eventually we can merge those two codebases as well",
        "ts": "1467902676.001582"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "or use a better interface",
        "ts": "1467902683.001583"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "now i need to figure out why exec doesn't finish",
        "ts": "1467902700.001584"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "oh there is still a reference to tx.Uuid",
        "ts": "1467902768.001585"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "how do i post an executedEvent?",
        "ts": "1467902790.001586"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "OH, i shouldn't implement the executor interface directly",
        "ts": "1467902869.001587"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "we really must stop putting all these interfaces into consenter",
        "ts": "1467902885.001588"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Absolutely, that consenter interface is in desperate need of an overhaul",
        "ts": "1467903033.001589"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The whole monolithic interface always bugged me.  The thing doing network communication really should not be the thing doing ledger access.  It's odd that those are tied together.",
        "ts": "1467903080.001590"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "why does the executor create a state transfer instance?",
        "ts": "1467903559.001591"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "god so messy",
        "ts": "1467903577.001592"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so much to stub out",
        "ts": "1467903590.001593"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so what happened right now is that the state transfer gets pulled in",
        "ts": "1467903939.001594"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "and with it all kinds of ledger code, etc.",
        "ts": "1467903945.001595"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "is there a way to decouple executor and state transfer?",
        "ts": "1467903964.001596"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Hmmm",
        "ts": "1467904194.001597"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, I think we need to ask where state transfer should live.",
        "ts": "1467904238.001598"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "In the new design, do we have state transfer for the PBFT log replication, or for the blockchain, or for both?",
        "ts": "1467904263.001599"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Leaving things largely as they stand today, I'd say we simply need to include a state transfer network API in addition to the execution network API",
        "ts": "1467904350.001600"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "This also begs the question of how we for instance get the value for our checkpoints? Is this still the blockinfo?",
        "ts": "1467904407.001601"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Really, I think we need to know what the network interface to the endorsers is",
        "ts": "1467904429.001602"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i think we just do consensus",
        "ts": "1467904641.001603"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "which means we need to do some minimal sort of state transfer for consensus",
        "ts": "1467904660.001604"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, state transfer is only on the PBFT log then?",
        "ts": "1467904685.001605"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "<@U0Y14MWA2>: ideas?",
        "ts": "1467904687.001606"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "do we even maintain a log?",
        "ts": "1467904695.001607"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i don't think so",
        "ts": "1467904697.001608"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "We do not.  Though it seems like we must, in order to 'do consensus'",
        "ts": "1467904730.001609"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "why?",
        "ts": "1467904808.001610"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "we just do total order broadcast",
        "ts": "1467904823.001611"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "we really need to merge batch and core",
        "ts": "1467904915.001612"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "True.  I'm unsure then how we supply a state transfer target if there is a gap in our log",
        "ts": "1467904916.001613"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i just had a \"missing request\" issue",
        "ts": "1467904929.001614"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "odd",
        "ts": "1467904934.001615"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Yes, we do.  I know that <@U0XQ35CDD> is eager to do this, and I told him we could wait until his return.",
        "ts": "1467904935.001616"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so for doing total order, we don't need to maintain a log",
        "ts": "1467904969.001617"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I really need to understand this network interface",
        "ts": "1467904990.001618"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "but if all endorsers\/peers miss a broadcast block, it is lost forever",
        "ts": "1467905006.001619"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Does everyone get ordering messages from all consenters? Or do they subscribe to a particular one",
        "ts": "1467905011.001620"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "unclear yet",
        "ts": "1467905025.001621"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i would say, you connect to the consenter cloud",
        "ts": "1467905038.001622"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "maybe to one particular one",
        "ts": "1467905044.001623"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "does it matter?",
        "ts": "1467905051.001624"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I would say yes.",
        "ts": "1467905056.001625"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Because a byzantine attack can certainly cause a particular consenter to end up with a gap in the log it broadcasts",
        "ts": "1467905082.001626"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "(unless we store and somehow state transfer this log)",
        "ts": "1467905093.001627"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "right",
        "ts": "1467905109.001628"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Or, ignore the byzantine attack, it could happen under more benign conditions as we have seen.",
        "ts": "1467905112.001629"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so when a peer connects to the consensus cloud, it needs to be able to retrieve a partial log",
        "ts": "1467905152.001630"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I believe traditionally, with log replication, you have periodic snapshots, which allows you to garbage collect the log, so that someone who connects either has recent enough state that their log overlaps with the available log, or, they retrieve that snapshot, and then can retrieve the log.",
        "ts": "1467905253.001631"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "or it has a way to retrieve blocks via some other mechanism",
        "ts": "1467905260.001632"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "honestly, i think somebody else needs to design and implement this",
        "ts": "1467905310.001633"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "'this'?",
        "ts": "1467905323.001634"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "logs, state transfer",
        "ts": "1467905345.001635"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "It all seems like so much duplication of the blockchain to me",
        "ts": "1467905472.001636"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The old executor service worked off the semi-synchronous deal of, send executions, periodically get back checkpoint values, and, send skips including the checkpoint value to skip to.  That would completely eliminate the need for us to log or state transfer, push it all back into the peer, and seems like it would work.  I'm not sure I love the semi-synchronous nature of it, but I'm struggling to think of anything better.",
        "ts": "1467905645.001637"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yes it does",
        "ts": "1467906352.001638"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "something is wrong with my code",
        "ts": "1467906394.001639"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "it doesn't execute right",
        "ts": "1467906400.001640"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "<@U0XPR4NP4>: can you give me some feedback on what i am doing wrong with the executor interface?",
        "ts": "1467907366.001641"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i don't see the execute getting through",
        "ts": "1467907378.001642"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Sure, let me pull your branch again",
        "ts": "1467907392.001643"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Can you point me where specifically you're not seeing execution?",
        "ts": "1467907588.001644"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "stuck in chan send in the executor",
        "ts": "1467907623.001645"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so manager is not running?",
        "ts": "1467907633.001646"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "You do need to explicitly start the executor, it does not start at construction",
        "ts": "1467907708.001647"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "(Starting the executor starts the backing event manager)",
        "ts": "1467907733.001648"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "oh.",
        "ts": "1467907752.001649"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "who starts it?",
        "ts": "1467907755.001650"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Helper starts it immediately after constructing it",
        "ts": "1467907783.001651"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "hmm",
        "ts": "1467907789.001652"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "odd",
        "ts": "1467907791.001653"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "why do you have to start it explicitly?",
        "ts": "1467907799.001654"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Having it automatically start creates garbage that must be cleaned up.  Especially for testing, we want the execution to take place on the testing thread, so we don't have to deal with synchronizing",
        "ts": "1467907843.001655"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Outside of the unit tests, the executor is effectively a singleton, so the additional work after constructing it didn't seem like a big deal",
        "ts": "1467907916.001656"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "aha",
        "ts": "1467908020.001657"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "okay",
        "ts": "1467908053.001658"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i'm checking out for today",
        "ts": "1467908058.001659"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "been at it already for 9h",
        "ts": "1467908074.001660"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "but it seems to work",
        "ts": "1467908084.001661"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "you can create a basic consensus network now",
        "ts": "1467908111.001662"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Great! Enjoy your evening",
        "ts": "1467908401.001663"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "<@U0XPR4NP4>: i just pushed a deploy script",
        "ts": "1467909914.001664"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "<@U0XR6J961> <@U0XPR4NP4> ok there are a few things here",
        "ts": "1467910402.001665"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "1) *what is the state of consensus (PBFT)?* The state is only the internal PBFT state - for example: the set of consenters, view number, sequence numbers, P, Q sets and similar. Things related to the ledger (e.g., raw ledger) are not required.",
        "ts": "1467910507.001666"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "That said, our implementation of consensus may decide to offer more than the spec - for example, consensus service could (perhaps only best-effort) cash the last K blocks of the raw ledger.",
        "ts": "1467910579.001667"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "There might be additional call (not present in the current API) to get those blocks - but I would say this is not \"Phase 1\"",
        "ts": "1467910614.001668"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "my concern is that if we do not persist the raw blocks we `deliver()`, these blocks might be lost",
        "ts": "1467910624.001669"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "This is not our issue - strictly speaking",
        "ts": "1467910635.001670"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yea",
        "ts": "1467910641.001671"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "this is the issue of peers",
        "ts": "1467910649.001672"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "some cash needs to exist though in order not to loose all messages",
        "ts": "1467910663.001673"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "in case of catastrophes",
        "ts": "1467910675.001674"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "that is true",
        "ts": "1467910677.001675"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "well if we consider the consensus network as \"miners\", we need to retain the chain",
        "ts": "1467910678.001676"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok, so this is one thing to consider. However one thing is important - this ledger cache if implemented - must not block PBFT \"state transfer\" among consenters if you see what I mean",
        "ts": "1467910759.001677"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yes",
        "ts": "1467910774.001678"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "pbft does not need it for its own operation",
        "ts": "1467910782.001679"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "we need to entirely decouple the functionality related to PBFT operation and optional raw ledger cache",
        "ts": "1467910789.001680"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "We should look how Kafka is doing this - this exists",
        "ts": "1467910809.001681"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so other points",
        "ts": "1467910820.001682"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "2) *To how many consenters peer connects*. This is another important one. The first step is to decouple PBFT from peer and in that decoupling we will have first peer trusting the consenter it connects to.",
        "ts": "1467910884.001683"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "Of course this is not sufficient",
        "ts": "1467910890.001684"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "in general",
        "ts": "1467910894.001685"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "the first step is done",
        "ts": "1467910901.001686"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "pbft runs in a separate process, maintains a separate network",
        "ts": "1467910914.001687"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "and there is a client \"library\" that provides `Broadcast()` and `Deliver()`",
        "ts": "1467910936.001688"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "great - so then we need to *ADD* the functionality that was not there in v0.5 by which a peer *optionally* connects to different consenters if the current one does not work",
        "ts": "1467910953.001689"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yes, we can do that",
        "ts": "1467910977.001690"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i'd say the peer needs to do that, using the library",
        "ts": "1467910994.001691"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "by the way this is optional as organization maintaining several peers *and* a consenter - may always trust its peer - so this will improve those peers perfromance and simlify their execution path",
        "ts": "1467911010.001692"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "now in the general case",
        "ts": "1467911020.001693"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "we need other things that are not there yet - such as",
        "ts": "1467911033.001694"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "a) as we do not have signatures in Commit messages - a peer must always connect to at least *f+1* consenters and get their confirmations before the library outputs deliver()",
        "ts": "1467911084.001695"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "b) if we introduce signatures on commit - we could have a peer tentatively \"trusting\" a single consenter and waiting for the latter to forward him the commit certificate",
        "ts": "1467911133.001696"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "the latter can be silent in which case the peer would connect to another consenter",
        "ts": "1467911153.001697"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "now obviously - we have a choice",
        "ts": "1467911163.001698"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "if we sign on commit, then we can include the certificate directly",
        "ts": "1467911190.001699"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "a) introduce signatures - or go for f+1 stuff",
        "ts": "1467911195.001700"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "you mean if you sign commit msgs?",
        "ts": "1467911208.001701"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yes",
        "ts": "1467911212.001702"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "yes, then once you assemble commit certificate you could forward to client",
        "ts": "1467911228.001703"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "this is actually the \"only\" way to properly do it if we want to avoid connecting to f+1 or more consenters",
        "ts": "1467911265.001704"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "yea",
        "ts": "1467911271.001705"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "what is your take on the tradeoff?",
        "ts": "1467911273.001706"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "f+1 vs signatures?",
        "ts": "1467911277.001707"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "i'm for signing",
        "ts": "1467911279.001708"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "better scale",
        "ts": "1467911284.001709"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "allows distribution tree",
        "ts": "1467911289.001710"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "it seemingly does - we need to see where to sign though - commit msg is an obvious one but not the only one",
        "ts": "1467911343.001711"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I'm still in favor of signing checkpoint messages",
        "ts": "1467911359.001712"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "With those corresponding to blocks",
        "ts": "1467911375.001713"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "so that would effectively be a 4th phase",
        "ts": "1467911415.001714"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so we should make a plan on how do we proceed with these additions that we have on current code which stem from the fact that consensus client (peer) is not tied to a consenter (esp. trust-wise)",
        "ts": "1467911489.001715"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Effectively.  But by separating it from the standard commit path, you could effectively tweak the rate of signatures by modifying the checkpoint interval.",
        "ts": "1467911504.001716"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "but if we can only deliver() what has a certificate, that doesn't help us",
        "ts": "1467911531.001717"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "signing chkpoint is possible but then client\/peer connecting to a single consenter would output a burst  of deliver() events only every checkpoint",
        "ts": "1467911535.001718"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "we still need to wait for a certificate",
        "ts": "1467911538.001719"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "but",
        "ts": "1467911540.001720"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "checkpoint is sufficient",
        "ts": "1467911545.001721"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "yet not necessary",
        "ts": "1467911548.001722"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "which means that we can just increase our batch size",
        "ts": "1467911558.001723"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "f+1 signatures upon commit are sufficient",
        "ts": "1467911560.001724"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so it is like 2f+1 commit signatures",
        "ts": "1467911568.001725"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "or f+1 4th phase signatures",
        "ts": "1467911574.001726"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I don't see why we could not deliver periodically, with a separate commit phase",
        "ts": "1467911576.001727"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "latency",
        "ts": "1467911585.001728"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Set k=1 and you're to the behavior of signatures on commit",
        "ts": "1467911610.001729"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "we would be blowing it up for no strong reason + issues if there is not enough traffic",
        "ts": "1467911615.001730"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "But it allows people to trade some latency for some throughput",
        "ts": "1467911618.001731"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so, again, for this particular feature checkpoint is an overkill",
        "ts": "1467911648.001732"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "f+1 \"4th phase\" signatures suffice",
        "ts": "1467911657.001733"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "or 2f+1 commit signatures (transferable commit certificate)",
        "ts": "1467911674.001734"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "now, in future, as we go for large number of consenters, this may need to be revisited",
        "ts": "1467911724.001735"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "client would need to verify for n=100 at least 34 signatures",
        "ts": "1467911742.001736"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "but also otherwise connect to 34 consenters",
        "ts": "1467911758.001737"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "it will certainly be a challenge to properly scale this - but lets have something more basic for Phase 1 (end of September)",
        "ts": "1467911799.001738"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "and worry about scalability in Phases 2 and 3",
        "ts": "1467911808.001739"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "this emphasizes the need to have the trust of a peer (consensus client) into consenters configurable",
        "ts": "1467912505.001740"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "at one extreme we will have peer trusting \"his\" consenter (very efficient - not very robust)",
        "ts": "1467912530.001741"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "at the other extreme we have the above (f+1 connections or  a connections with f+1 or 2f+1 signature verifications) - (very robust - not very efficient)",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467912648.000000"
        },
        "ts": "1467912594.001742"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "one can easily imagine peer\/consenter trust policies in between - but practically they may be less appealing",
        "ts": "1467912626.001743"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "maybe the cryptographers have a way to compact all these signatures",
        "ts": "1467912765.001745"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "ok, i gotta go outside",
        "ts": "1467912819.001746"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "staring too much into the screen",
        "ts": "1467912823.001747"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "yes - lets discuss this later on further",
        "ts": "1467912835.001748"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "we'll get it right :slightly_smiling_face:",
        "ts": "1467912843.001749"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "just to conclude for  this iteration - I do not particularly like signing commit msgs - but we may want to sign the 4th phase instead",
        "ts": "1467912930.001750"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "reasons next time :wink:",
        "ts": "1467912935.001751"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I'm looking at the virtual client \/ slot stuff again, and I'm wondering about recovering after getting out of sync with the network.  Namely, today, we discard our outstanding requests when we get out of sync with the network, as we may have missed their executions",
        "ts": "1467915519.001752"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "In an ideal world, we would somehow encode the counter each slot has executed to somehow, either in the checkpoint, or in the consensus metadata, so that we could intelligently decide whether a particular request has been executed or not, rather than simply discarding them",
        "ts": "1467915610.001753"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The problem I am coming up with, is that as the number of allowed outstanding requests goes up, and the number of replicas goes up, this could become quite large.",
        "ts": "1467915636.001754"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Since each counter is 64 bit, were we to allow 1000 outstanding requests per replica (I think this is the upper end of what is reasonable, but possible), then we would have 8KB of counter data per replica",
        "ts": "1467915680.001755"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "I lost the context a bit - is this still relevant for v2? Asking since you talk about execution...",
        "ts": "1467915706.001756"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Yes, this is.  This comes back to the idea that, per the PBFT paper, a client should submit requests one at a time, and wait for the execution to complete.",
        "ts": "1467915745.001757"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Because the consenters are acting as clients, we can't reasonably only have one outstanding request per consenter.",
        "ts": "1467915791.001758"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "how come they act as clients? they will normally not broadcast -except perhaps for some maintenance\/reconfiguration operations",
        "ts": "1467915841.001759"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I guess we could re-evaluate for v2, but, assuming you want an endorser to be able to connect to a single consenter and pass in transactions",
        "ts": "1467915892.001760"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Then that single consenter needs to act as the PBFT client, broadcasting the PBFT request to the consenting network.",
        "ts": "1467915923.001761"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "in this case the replica\/consenter is merely a proxy not a client",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467915973.000000"
        },
        "ts": "1467915936.001762"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so the broadcaster stays the client (peer)",
        "ts": "1467915946.001763"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Sure, the consenter is not originating the request, but it is the one who is assuming responsibility for it, waiting for its execution to complete before submitting a new request",
        "ts": "1467915975.001765"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "not really",
        "ts": "1467915988.001766"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Or rather, before proxying a new request if you prefer",
        "ts": "1467915990.001767"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "it should not wait for that IMO",
        "ts": "1467915999.001768"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "How then, do you prevent censorship?",
        "ts": "1467916012.001769"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "remind me of the problem?",
        "ts": "1467916020.001770"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "A consenter broadcasts this proxied request to the network.",
        "ts": "1467916078.001771"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Each receiving replica must first decide whether this request has been executed or not.  Because it's possible the network has already done the 3 phase protocol for this request, before the broadcast reaches every replica.",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1467916128.000000"
        },
        "ts": "1467916112.001772"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "normally there are client timestamps for this",
        "ts": "1467916138.001775"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "also in PBFT",
        "ts": "1467916142.001776"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Yes! There are... but it exposes us to potential censorship without the waiting approach",
        "ts": "1467916160.001777"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok listening :slightly_smiling_face:",
        "ts": "1467916170.001778"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, it is easy enough, for the receiving replica to check the timestamp of the request against the timestamp of the most recently executed request, and, if the timestamp is older, to discard, and this is our current behavior.",
        "ts": "1467916199.001779"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so far so good",
        "ts": "1467916214.001780"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Now, imagine that a replica broadcasts two requests to the network, request A with timestamp of 1, and request B with timestamp of 2",
        "ts": "1467916244.001781"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The primary byzantinely wants to censor request A, so, it first orders request B",
        "ts": "1467916276.001782"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Now, the network executes B, so, any replica which receives request A will believe it is stale and already executed, and discard it.",
        "ts": "1467916326.001783"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok, right so there are two things here",
        "ts": "1467916349.001784"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "first if consenter = proxy not client",
        "ts": "1467916361.001785"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "then we can have client still have 1 outstanding request as different proxied requests will have different timestamp (clientID,clientTimestamp)",
        "ts": "1467916391.001786"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so that would be still ok - you do not need 1 request proxied at the time",
        "ts": "1467916407.001787"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "now",
        "ts": "1467916409.001788"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "to allow the client\/peer to broadcast requests in paralel we do face the issue you mention",
        "ts": "1467916438.001789"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "and in that case we need FIFO for client requests",
        "ts": "1467916450.001790"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Ah, so, I had a different implementation idea",
        "ts": "1467916465.001791"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok, listening :slightly_smiling_face:",
        "ts": "1467916472.001792"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "That does not require FIFO",
        "ts": "1467916473.001793"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "BTW FIFO may be of independent interest",
        "ts": "1467916492.001794"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "as aguarantee to clients",
        "ts": "1467916497.001795"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "but go on",
        "ts": "1467916500.001796"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, each replica maintains some number of \"virtual client ids\", I usually refer to them as 'slots', as there are a fixed number of them and they are occupied or vacant.",
        "ts": "1467916519.001797"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "(because one request at the time somehow gives FIFO - so we may want to maintain that if we go for multiple \"paralell broadcasts\")",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467916547.000000"
        },
        "ts": "1467916526.001798"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "When a request is proxied, the replica looks for an empty slot, and assigns the request that virtual client ID before broadcasting to the network",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1467916558.000000"
        },
        "ts": "1467916550.001800"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Each slot has a slot local counter (akin to a timestamp), and the promise is that a non-byzantine replica will never broadcast two requests with the same slot number until the previous request has prepared",
        "ts": "1467916616.001802"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok so slot is like a window? shared by many clients or 1 window per client?",
        "ts": "1467916643.001803"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Sort of like a window I suppose, potentially shared by many clients.",
        "ts": "1467916722.001804"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The number of slots is the number of total outstanding requests allowed for each replica",
        "ts": "1467916739.001805"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "And the replica might choose to allocate all slots to a single client, or to distribute them among many clients",
        "ts": "1467916752.001806"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "hm, this may already be limiting if we have a lot of clients but they are fine with broadcasting 1 request at the time",
        "ts": "1467916783.001807"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "but go on",
        "ts": "1467916788.001808"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Slots hold requests which are not prepared.  Once a request is prepared, the last prepared counter associated with that slot is set to the value of the counter for the request that was prepared.  Any request which is received who's counter is less than this last prepared counter will be assumed to be stale, and discarded.",
        "ts": "1467916927.001809"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "This prevents any request from being multiply executed.",
        "ts": "1467916947.001810"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Because no new requests are sent for a slot until that request is prepared, it is easy to run a timer against the slot to detect censorship.",
        "ts": "1467916991.001811"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "And the degree of parallelism is controlled by the number of slots.",
        "ts": "1467917015.001812"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "i was wondering could we simply view change the leader who order request with timestamp 2 instead of 1 for given client",
        "ts": "1467917028.001813"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "and basically track per client the last sequence number",
        "ts": "1467917041.001814"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Ah, if we have FIFO, we could",
        "ts": "1467917048.001815"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so this would be somehow implementing fifo, no?",
        "ts": "1467917058.001816"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "primary would put an advance request n+2 in some queue and not actually process it unless n+1 is processed",
        "ts": "1467917106.001817"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "to prevent DoS the n+k above could be limited by k",
        "ts": "1467917119.001818"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "which is the number of outstanding reqs a client may have",
        "ts": "1467917129.001819"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "hard coded - to begin with",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467917145.000000"
        },
        "ts": "1467917132.001820"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "now k=1",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467917153.000000"
        },
        "ts": "1467917134.001821"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Hmmm, let me think",
        "ts": "1467917186.001824"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "sure - I need to transfer to France v. Germany",
        "ts": "1467917202.001825"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The tricky part abou this implementation",
        "ts": "1467917205.001826"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "but will be back :slightly_smiling_face:",
        "ts": "1467917205.001827"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Is that the primary does not necessarily send pre-prepares in order",
        "ts": "1467917217.001828"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So to conclude whether the primary is sequentially ordering requests gets trickier",
        "ts": "1467917236.001829"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "yes so this would be making it to look at client timestamp and actually do them in order",
        "ts": "1467917236.001830"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "I think it would be vital to enforce FIFO if we allow parallel requests",
        "ts": "1467917254.001831"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "not sure submitting peer would like it differently...",
        "ts": "1467917266.001832"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "But imagine that client submits reqs A,B,C with increasing timestamps.",
        "ts": "1467917315.001833"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The primary orders B,C into seqNo=3, but has not sent preprepare for seqNo=2 yet",
        "ts": "1467917354.001834"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The network will prepare and commit this, because there's nothing obviously wrong with it.",
        "ts": "1467917375.001835"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok, yes so we would need to eliminate this watermark thingy",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467917553.000000"
        },
        "ts": "1467917392.001836"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "and basically rely on batching for throughput optimisation",
        "ts": "1467917402.001837"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "and do batches 1 by 1",
        "ts": "1467917407.001838"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Yes, we could do this, but it would be a pretty significant change",
        "ts": "1467917428.001839"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "not necessarily bad... and it can be easy to try out (by hardocding watermarks)",
        "ts": "1467917452.001840"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "to H=L+1",
        "edited": {
            "user": "U0Y14MWA2",
            "ts": "1467917466.000000"
        },
        "ts": "1467917457.001841"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "or H=L not sure how that goes",
        "ts": "1467917481.001843"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "side comment: I remember talking to Alysson Bessani (lead of BFT Smart) - he told me they eliminated watermarks early on...",
        "ts": "1467917525.001844"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Interesting.  I think we could certainly completely eliminate watermarks if we assume an underlying FIFO stream",
        "ts": "1467917553.001845"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "But, we do have working watermarks today.  I really think we could switch to UDP transports, and things would continue to work.",
        "ts": "1467917607.001847"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "that might be more straightforward to do - put H=L and make primary order things from clients one by one",
        "ts": "1467917628.001848"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "well we may have both",
        "ts": "1467917632.001849"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "just a note to system admins",
        "ts": "1467917637.001850"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "do not put H!=L (watermarks) and K&gt;1 (paralel req FIFO) at the same time",
        "ts": "1467917673.001851"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I don't know, I think we should commit one way or the other",
        "ts": "1467917727.001852"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The additional code complexity of supporting both windowed and non-windowed modes seems like a waste",
        "ts": "1467917741.001853"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "ok, I think watermarks may have limited use - it was PBFT way of doing batching",
        "ts": "1467917747.001854"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "so batching handles that",
        "ts": "1467917758.001855"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "and then paralel FIFO is not too complex",
        "ts": "1467917769.001856"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "with primary needing to look at client ts and do +1",
        "ts": "1467917778.001857"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "that queue might be problematic",
        "ts": "1467917787.001858"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "but I would limit it to K",
        "ts": "1467917793.001859"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "hard coded",
        "ts": "1467917797.001860"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "for all clients",
        "ts": "1467917803.001861"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "later on one could play with more flexible Ks",
        "ts": "1467917815.001862"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "need to take off",
        "ts": "1467917854.001863"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "thanks for the discussion",
        "ts": "1467917858.001864"
    },
    {
        "type": "message",
        "user": "U0Y14MWA2",
        "text": "will catch up later",
        "ts": "1467917861.001865"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Alright, thanks for the chat, will think on this",
        "ts": "1467917862.001866"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "<@U0Y14MWA2> Independent of all the of the discussion above.  In the Castro paper, each client submits a request one at a time, and the replica tracks the timestamp per replica to determine whether it should send a view change or not.  It is somewhat handwaved away that this information could be stored on disk, but what is not clear to me, is how this information is updated during fall behind \/ catch up scenarios.  If a replica crashes after receiving a request and must do state transfer, does it discard its outstanding requests? If so, then what prevents a cascade of failures from censoring requests? Imagine 4 nodes, all receive a request, then vp0 crashes, recovers, discards outstanding, and then so do vp1,2,3 in sequence.  At this point, all outstanding requests have been discarded, and the request may have, or may not have executed.  To me, the correct way to handle this, is to track the last executed request for each client, and somehow have this recovered via state transfer.  My problem here is, as they mention, there could be lots of clients, so recovering this data via state transfer might be very expensive indeed.",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1467922286.000000"
        },
        "ts": "1467918795.001867"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "the client is responsible for resubmitting the request?",
        "ts": "1467926727.001869"
    },
    {
        "type": "message",
        "user": "U0XR6J961",
        "text": "make `broadcast()` a RPC (it is already) and have it return only when the request has been prepared",
        "ts": "1467926774.001870"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "We could certainly require the client to resubmit it.  But I think we need to clearly define that as part of the v2 architecture then",
        "ts": "1467927208.001871"
    }
]