[
    {
        "type": "message",
        "user": "U0ZR63HLK",
        "text": "<@U0XQ35CDD> thanks :slightly_smiling_face:",
        "ts": "1476949446.002272"
    },
    {
        "type": "message",
        "user": "U0ZR63HLK",
        "text": "There is an IBM page (<https:\/\/developer.ibm.com\/hadoop\/2016\/07\/20\/kafka-acls\/>) that describes ACLs in Kafka. Really nice. For topics, ACLs can configured on the following operations: CREATE\/READ\/WRITE\/DESCRIBE.",
        "attachments": [
            {
                "service_name": "Hadoop Dev",
                "title": "Kafka ACLs - Hadoop Dev",
                "title_link": "https:\/\/developer.ibm.com\/hadoop\/2016\/07\/20\/kafka-acls\/",
                "text": "Kafka ACLs when SSL and Kerberos are enabled",
                "fallback": "Hadoop Dev: Kafka ACLs - Hadoop Dev",
                "image_url": "https:\/\/developer.ibm.com\/hadoop\/wp-content\/uploads\/sites\/28\/2016\/06\/kafka-broker.jpg",
                "ts": 1469023544,
                "from_url": "https:\/\/developer.ibm.com\/hadoop\/2016\/07\/20\/kafka-acls\/",
                "image_width": 839,
                "image_height": 250,
                "image_bytes": 27994,
                "service_icon": "https:\/\/developer.ibm.com\/hadoop\/wp-content\/themes\/projectnext\/css\/favicon.ico",
                "id": 1
            }
        ],
        "ts": "1476953605.002273"
    },
    {
        "type": "message",
        "user": "U0ZR63HLK",
        "text": "So, the Kafka cluster administrator can decide who is allowed to create topics. Nice!",
        "ts": "1476953632.002275"
    },
    {
        "type": "message",
        "user": "U0PB67X4K",
        "text": "Just catching up on this conversation as I was trapped in meetings yesterday.",
        "ts": "1476959930.002276"
    },
    {
        "type": "message",
        "user": "U0PB67X4K",
        "text": "I assume that you do know that it is possible to right your own authorization plugin for Kafka (the default simple authorizer does store ACLs in ZK)?",
        "edited": {
            "user": "U0PB67X4K",
            "ts": "1476959997.000000"
        },
        "ts": "1476959976.002277"
    },
    {
        "type": "message",
        "user": "U0PB67X4K",
        "text": "and just to double-check, the plan is that each channel maps to a Kafka topic?",
        "ts": "1476960104.002279"
    },
    {
        "type": "message",
        "user": "U0ZR63HLK",
        "text": "yes, I have the same understanding",
        "ts": "1476961679.002280"
    },
    {
        "type": "message",
        "user": "U1AU8DRQR",
        "text": "guys, I am on sick leave today so I won't participate in the daily scrum. the SBFT thing was merged and my patch for it: <https:\/\/gerrit.hyperledger.org\/r\/#\/c\/1737\/> it only adds one time pull synchronization. <@U0UGH3X7X> <@U0XQ35CDD> <@U0Y14MWA2> <@U0XPR4NP4>",
        "edited": {
            "user": "U1AU8DRQR",
            "ts": "1476967197.000000"
        },
        "ts": "1476966768.002281"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "<@U0PB67X4K> I am well aware of that, and had also posted the relevant links for this in the crypto channel.",
        "ts": "1476967030.002282"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "RE: channel mapping to a Kafka topic - yes.",
        "ts": "1476967061.002283"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "( <@U0PB67X4K>: This is Option 2 in my write-up above.) ",
        "edited": {
            "user": "U0XQ35CDD",
            "ts": "1476967552.000000"
        },
        "ts": "1476967538.002285"
    },
    {
        "type": "message",
        "user": "U1KDAMDJ7",
        "text": "Is there an recommended convention for naming orderer nodes?",
        "ts": "1476970729.002287"
    },
    {
        "type": "message",
        "user": "U0UGH3X7X",
        "text": "for 0.6 yes , required naming vp0,vp1, etc ...  for v1.0 no, we should be able to map from certs",
        "ts": "1476971041.002288"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "<@U0UGH3X7X> post the hangout link here in case others want to join? ",
        "ts": "1476972043.002289"
    },
    {
        "type": "message",
        "user": "U0UGH3X7X",
        "text": "worked earlier today but not now !",
        "ts": "1476972070.002290"
    },
    {
        "text": "<@U0UGH3X7X|tuand> has started a Google+ Hangout for this channel. <https:\/\/hangouts.google.com\/hangouts\/_\/qdazmwzqg5apdlfx3suuutlutie|Join Hangout>.",
        "username": "hangouts",
        "bot_id": "B0UKUAJ0Y",
        "type": "message",
        "subtype": "bot_message",
        "ts": "1476972093.002291"
    },
    {
        "type": "message",
        "user": "U0ZR63HLK",
        "text": "<@U0XQ35CDD>, may you clarify me what is the shim in the context of Kafka? Sorry :disappointed:",
        "ts": "1476972137.002292"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "<@U0ZR63HLK>: Sure. It's essentially the middleman between the peers and the Kafka cluster. The peers issue Broadcast and Deliver RPCs and the shim turns them into the proper API calls for the Kafka cluster. See: <https:\/\/gerrit.hyperledger.org\/r\/#\/c\/1627\/>",
        "ts": "1476972911.002293"
    },
    {
        "type": "message",
        "user": "U0ZR63HLK",
        "text": "ah, perfet. Got it. Thanks :slightly_smiling_face:",
        "ts": "1476973138.002294"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Sure thing.",
        "ts": "1476973236.002295"
    },
    {
        "type": "message",
        "user": "U0UGH3X7X",
        "text": "working on FAB-665 (<https:\/\/jira.hyperledger.org\/browse\/FAB-665>)  which is a tool for admins to create the genesis block as defined for bootstrapping in FAB-359.  Also seeing how I can generate this block according to <@U0XPR4NP4> 's proposed ab.proto changeset ( <https:\/\/gerrit.hyperledger.org\/r\/#\/c\/1795\/1> )",
        "ts": "1476973261.002296"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "<@U0UGH3X7X> You are likely better off refering to <https:\/\/gerrit.hyperledger.org\/r\/#\/c\/1817\/>  as this generates a simple genesis block using those protos (statically, in code)",
        "ts": "1476973372.002297"
    },
    {
        "type": "message",
        "user": "U0UGH3X7X",
        "text": "thanks jason ! 1817 is on a tab somewhere on my desktop :slightly_smiling_face:",
        "ts": "1476973443.002298"
    },
    {
        "type": "message",
        "user": "U1BC5A0F9",
        "text": "Hi, so <@U0XQ35CDD>, does it mean that shim is able to update the ACLs? If so, would it be responsible for processing a specific type of transaction, e.g., configuration one?",
        "ts": "1476973801.002299"
    },
    {
        "type": "message",
        "user": "U1BC5A0F9",
        "text": "For example if a channel is owned be two parties, it may be that both of them need to \"agree\" to have  the ACL extended by one party or have the ACL reduced by one or more parties.",
        "ts": "1476973851.002300"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "<@U1BC5A0F9>: The shim should be able to update the ACLs, and it would be responsible for processing the CONFIG tx, yes.",
        "ts": "1476979063.002301"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "<@U0XQ35CDD> I've heard it proposed that the Kafka shim will need to maintain a copy of the rawledger (to support (re)configuration, and to allow the possibility of infinite block retention).  If this is the case, then it seems like each channel would have one consumer, writing to the rawledger, and then clients would read from this rawledger (not spawning a consumer per client).  I know you have (understandably) expressed an interest to try to keep the kafka mappings as 1-1 and not re-invent functionality, so I wanted to check to see if you agree this is the plan or if you propose some alternative?",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476990614.000000"
        },
        "ts": "1476990603.002302"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "<@U0XPR4NP4> I'm not sure I agree with this, but maybe I'm missing something.",
        "ts": "1476991640.002304"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "For infinite block retention, my intention was to simply set `log.retention.hours=2147483647` in Kafka itself. This is approx. 250,000 years.",
        "ts": "1476991726.002305"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "&gt; If this is the case, then it seems like each channel would have one consumer, writing to the rawledger, and then clients would read from this rawledger (not spawning a consumer per client).",
        "ts": "1476991771.002306"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Can you expand on this explanation? If a channel has one consumer, then this is one of the shim-carrying nodes. Which one? And doesn't this mean you have to worry about this node crashing, etc. (basically recreate the problem that the cluster was set to solve)?",
        "ts": "1476991888.002307"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Ah, yes, so, careless wording.  I should have said \"seems like each channel would have one consumer _per shim_, writing to the rawledger\".  I would correspondingly assume that there would be one producer per channel, per shim, rather than spawning a new one per client.",
        "ts": "1476992030.002308"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The piece which seems most problematic trying to keep the 1-1 mapping of broadcaster&lt;-&gt;producer and deliverer&lt;-&gt;consumer is that because the blockstream contains configuration, it must be parsed.  The producers and consumers are not truly independent, the current block height may affect the behavior of them both.  (The particular problem I am thinking of, is who is allowed to broadcast\/deliver to a chain) <@U0XQ35CDD>",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476992557.000000"
        },
        "ts": "1476992323.002309"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I suppose just as the plan is for block cutting, the shims could share a channel where they post chain\/channel reconfigurations, this could be dodged.",
        "ts": "1476992750.002313"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I think I will backtrack and say the more I think about this, the more I am convinced that we should keep the 1-1 passthrough.",
        "ts": "1476992789.002314"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "&gt; I suppose just as the plan is for block cutting, the shims could share a channel where they post chain\/channel reconfigurations, this could be dodged.",
        "ts": "1476993560.002316"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Right, if you look at Option 4 (<https:\/\/hyperledgerproject.slack.com\/archives\/fabric-consensus-dev\/p1476807224002206>) that's the thinking.",
        "attachments": [
            {
                "from_url": "https:\/\/hyperledgerproject.slack.com\/archives\/fabric-consensus-dev\/p1476807224002206",
                "fallback": "[October 18th, 2016 9:13 AM] kostas: 4. Have the shims maintain the ACL (and all other related config metadata), but don't go with ZK, etcd, or any custom consensus mechanism between them. Instead, use a special Kafka topic for such kind of config metadata. The shims write to a special Kafka topic\/partition, and apply the ACL once they've read it back from the partition.",
                "ts": "1476807224.002206",
                "author_subname": "kostas",
                "channel_id": "C0Z4NBUN6",
                "channel_name": "fabric-consensus-dev",
                "is_msg_unfurl": true,
                "text": "4. Have the shims maintain the ACL (and all other related config metadata), but don't go with ZK, etcd, or any custom consensus mechanism between them. Instead, use a special Kafka topic for such kind of config metadata. The shims write to a special Kafka topic\/partition, and apply the ACL once they've read it back from the partition.",
                "author_name": "Kostas Christidis",
                "author_link": "https:\/\/hyperledgerproject.slack.com\/team\/kostas",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2016-04-05\/31983107923_80db5353e9278df980c7_48.png",
                "mrkdwn_in": [
                    "text"
                ],
                "id": 1,
                "footer": "Posted in #fabric-consensus-dev"
            }
        ],
        "ts": "1476993580.002317"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "I'm still not sure we've addressed the concern though?",
        "ts": "1476993792.002319"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Perhaps not entirely.  I think maybe what I need to see is exactly how block cutting is going to work.",
        "ts": "1476993841.002321"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The reason why I started this conversation is I was thinking trying to unify the Kafka\/Solo common components into a single codebase would be a good idea.  Where the Kafka shim is simply populating a local rawledger, this would be a trivial exercise, however, after some thought, I'm inclined to agree with you, that that's the wrong way to do this.",
        "ts": "1476994054.002322"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "So, right, in Kafka mode, is there any reason not have the rawledger reside in a partition? Think of a topic with 2 partitions. In partition A you push all the transactions as you receive them by the clients, and then the timeout triggers (or the batch size threshold) and you send a message to cut for block X. When you read it back, you know which messages comprise block X and you can push block X to partition B, effectively making partition B your raw ledger. Of course the problem is the usual one: how do you prevent other shims from pushing the same block to partition B and thus ruining your chain. We can add some logic to the shins for this (and hey, option 3 would be nice) but we need to do it right.",
        "ts": "1476994552.002323"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Maybe we should have the shim populate a rawledger after all? (Great, now you agree with my first thought, and now I agree with your first thought.)",
        "ts": "1476994644.002324"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "The problem is that whereas multiple \"let's cut for block X\" messages in partition A are harmless, that's not the case for partition B.",
        "ts": "1476994690.002325"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "&gt; and then the timeout triggers (or the batch size threshold) and you\n\nWho's timer? Who is you? (Assuming multiple shims)\n\n&gt; and you send a message to cut for block X. \n\nIs this to a special topic? Or the same channel?",
        "ts": "1476994721.002326"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "You are a shim.",
        "ts": "1476994760.002327"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Has to be the same partition where the messages flow.",
        "ts": "1476994779.002328"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So you have a partition for a channel, and shims broadcast messages to this partition, not blocks.",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476994901.000000"
        },
        "ts": "1476994881.002329"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "When a shim broadcasts a message to a partition, it starts a timer for when to cut the batch.",
        "ts": "1476994974.002331"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Now, does the shim track to see whether that batch is cut? Or does it send the cut message regardless?",
        "ts": "1476995008.002332"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Or does the timer start when a batch is cut?",
        "ts": "1476995080.002333"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "If it reads a cut message, before it sends its own I would expect it to stay silent.",
        "ts": "1476995102.002334"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So then, the shim must have a consumer for every topic it broadcasts to?",
        "ts": "1476995126.002335"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Yes.",
        "ts": "1476995151.002336"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Okay, so there's a special dedicated per topic consumer for each shim, and then additional consumers are spawned per deliver call?",
        "ts": "1476995196.002337"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Ah, wait, but deliver does not consume from that topic, it must be a different one, with the blocks?",
        "ts": "1476995273.002338"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "The special consumers are for the shim to figure out when certain changes (ACL, blocks) take effect. The normal consumers are spawned to serve Deliver RPCs.",
        "ts": "1476995300.002339"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "It must be the one with the blocks, yes.",
        "ts": "1476995315.002340"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "This can be easily be a partition on the same topic by the way. ",
        "ts": "1476995339.002341"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Okay, so, then does the shim need a consumer for _every_ partition, regardless of whether it is broadcasting to it at this time? Or is there a dedicated topic which maintains the config across channels?",
        "ts": "1476995382.002342"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "And who's responsibility is it to put the block onto the block channel?",
        "ts": "1476995407.002343"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "So that last question brings me to this observation\/problem:",
        "ts": "1476995447.002344"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "Hey, sorry for barging in while you're discussing kafka stuff, but I have a question regarding multiChannels and I assume this is the best channel (pun intended) to ask - is there anyone here that knows more about the plan of how multi-channels will be implemented, besides what's written in Binh's google doc (which I've read)",
        "ts": "1476995448.002345"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "something doesn't add up :neutral_face:",
        "ts": "1476995482.002346"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "What's the specific question?",
        "ts": "1476995491.002347"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "(Jason, will resume.)",
        "ts": "1476995505.002348"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "well- where is the replication support, how can it be done?",
        "ts": "1476995509.002349"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "we decided long ago that peers that join or were offline for a while, get data from fellow peers",
        "ts": "1476995529.002350"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Ah, in short, it was decided that tracking which peers were to subscribe to which channel is a function of the app.  So the only piece of code which knows which peers are active on which channels would be the app",
        "ts": "1476995644.002351"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "It is also said:\n```\nIf the channel already exists, the list of Participants is the replacement of the existing list. The Orderers automatically replace the subscribers and eventually deliver the transaction together with other transactions on this channel.\n```\nThis sounds like a problem. If I'm a peer and I didn't get a participant update about a *removal* of a peer from a channel I may replicate information to it",
        "ts": "1476995676.002352"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "It could be that we need to add some other information when a peer is bootstrapped to a chain, indicating which other peers it is allowed to discuss this chain\/channel with",
        "ts": "1476995687.002353"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "what app? the chaincode?",
        "ts": "1476995701.002354"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "No, the application, the thing using the chaincode",
        "ts": "1476995710.002355"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Channel membership is done at a participant\/org level, not a peer level",
        "ts": "1476995719.002356"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "the node SDK then",
        "ts": "1476995729.002357"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "The app using the node SDK. ",
        "ts": "1476995744.002358"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "yeah",
        "ts": "1476995752.002359"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Any peer with a chain of trust to a participant CA is allowed to broadcast\/deliver on that channel",
        "ts": "1476995762.002360"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "But not every peer will want to transact on every channel",
        "ts": "1476995776.002361"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, it is the application (built on the SDK) which decides which peers will have a copy of the contents of which channels",
        "ts": "1476995795.002362"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I'm asking only regarding data replication between peers",
        "ts": "1476995795.002363"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Right",
        "ts": "1476995801.002364"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I'm a peer and a peer asks a block from me. how do I know i'm allowed to send it to him?",
        "ts": "1476995831.002365"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I think there may be a shortcoming in the design from this respect, that there should be an API for the app to inform the peer of possible sync sources and destinations",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476995851.000000"
        },
        "ts": "1476995836.002366"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "(a block from a chain of a channel)",
        "ts": "1476995840.002367"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "but, the only way of distributing such information has to be via a transaction, right?",
        "ts": "1476995876.002369"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Why?",
        "ts": "1476995882.002370"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "how else you suppose to do that then?",
        "ts": "1476995890.002371"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "The app must inform a peer to subscribe to a channel",
        "ts": "1476995904.002372"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "This expressly cannot be done via another chain, because it would leak that information via that chain",
        "ts": "1476995917.002373"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "you can't have an app contact peers and tell them about membership, it won't work.",
        "ts": "1476995941.002374"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "and not a good idea- what about peers that are unavailable at that moment?",
        "ts": "1476995951.002375"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "but are part of the channel?",
        "ts": "1476995955.002376"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "What is the problem with that?",
        "ts": "1476995962.002377"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "maybe I should bring these question up in the google doc or something",
        "ts": "1476995970.002378"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I was just checking maybe I didn't understand something",
        "ts": "1476995979.002379"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Wait, what's the counter-argument for posting the reconfig in the channel again?",
        "ts": "1476995998.002380"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "the counter argument is that I claim that the membership set *cannot* reduce in size, only extend",
        "ts": "1476996026.002381"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "wait, I mean- that's not a counter argument, but that's what I'm saying",
        "ts": "1476996067.002382"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "There is nothing which prevents the peers from maintaining a list of peers on the chain who are transacting there.",
        "ts": "1476996103.002383"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I meant that you could not maintain the membership on a different chain",
        "ts": "1476996116.002384"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "you're right but I'm saying the list cannot throw nodes out of it, only grow",
        "ts": "1476996166.002385"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "<@U0ZJZBJLF>: Because you may be lagging behind and when you reconnect you communicate with peers that may be removed from that channel?",
        "ts": "1476996173.002386"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "yes",
        "ts": "1476996180.002387"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "My concern is making the configuration too large.  Especially if the list cannot shrink, then with tens of thousands of peers over time, this could make the configuration transaction quite bloated, possibly problematically so",
        "ts": "1476996290.002388"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "lol tens of thousands of peers? we'll retire by that time",
        "ts": "1476996324.002389"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I don't think 10s of thousands is something anyone should worry about now",
        "ts": "1476996364.002390"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "If we are not architecting for that number, why are we even concerned about fetching older blocks peer to peer?",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476996392.000000"
        },
        "ts": "1476996379.002391"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "because a peer can join the network of any size, even of size 10",
        "ts": "1476996402.002393"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "and the consensus cannot bring that information to a new peer",
        "ts": "1476996424.002394"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "only fellow peers",
        "ts": "1476996426.002395"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "at least that's what I've been told will happen in v1.0, and since our team are taking care of the synchronization part and Binh told me we shouldn't send information to a peer that isn't authorized I'm concerned here",
        "ts": "1476996465.002396"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Here is a gut proposal which may have problems, but hear it out.  What if a peer could post a transaction to the chain, with its address\/identity, requesting that other peers contact it supply state transfer?",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476996515.000000"
        },
        "ts": "1476996498.002397"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I don't understand, can you elaborate?",
        "ts": "1476996532.002399"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Hmm, clever. ",
        "ts": "1476996534.002400"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, the fact that a peer is authorized to transact on a channel implies that it is authorized to receive the chain for that channel",
        "ts": "1476996552.002401"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "wait, that's a problem",
        "ts": "1476996567.002402"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "who decides which peer will fill the gaps to that peer that joined?",
        "ts": "1476996586.002403"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "it's either everyone, or you have a bystander effect",
        "ts": "1476996597.002404"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "(no one will)",
        "ts": "1476996605.002405"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "The peer gets offers and takes up one of the other peers on their offer?",
        "ts": "1476996638.002406"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "They would certainly not all have to send the blocks.  Just say \"Hi, ask me for blocks if you need them\"",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476996691.000000"
        },
        "ts": "1476996657.002407"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Exactly.",
        "ts": "1476996680.002408"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "so all peers gang up on him when he joins? doesn't sound very scalable, but now when I think of it- maybe I have an idea",
        "ts": "1476996707.002410"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "when you submit a block, that block is related to a channel right?",
        "ts": "1476996735.002411"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I mean, you don't mix transactions from different channels in the same block",
        "ts": "1476996747.002412"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Correct",
        "ts": "1476996755.002413"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "\"multi-ledger\"",
        "ts": "1476996757.002414"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "so... why not simply append the membership information with each block?",
        "ts": "1476996769.002415"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Every transaction on a chain must contain the same chain ID (and each channel has a unique chain ID)",
        "ts": "1476996781.002416"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "for example, the hash of all participant's PKI-ids",
        "ts": "1476996783.002417"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "by the consensus",
        "ts": "1476996791.002418"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "this solves it",
        "ts": "1476996805.002419"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I'm not sure I follow",
        "ts": "1476996816.002420"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Unless the reconfig message is posted to the chain, it doesn't. ",
        "ts": "1476996834.002421"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "it is.",
        "ts": "1476996842.002422"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I'll explain why",
        "ts": "1476996845.002423"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "And actually even then it doesn't I think.",
        "ts": "1476996846.002424"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Go for it. ",
        "ts": "1476996851.002425"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "let's say you're peer p0 and you're allowed to be in the channel until time T, ok?\nStarting from time T+epsilon, you're not allowed.",
        "ts": "1476996879.002426"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "each block sent after T, is sent without you in the membership of that block, and each block sent prior to time T, includes you in the block as an authorized peer",
        "ts": "1476996909.002427"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "let's say p1 is always part of the channel and p0 contacts p1 after T",
        "ts": "1476996927.002428"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "p0 should've received all block before T if he was alive at that time",
        "ts": "1476996944.002429"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "so it's \"safe\" to send blocks that were created before T to p0",
        "ts": "1476996956.002430"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "blocks that were created after T, won't be sent because the peer (p1) checks the list of the block he's about to send to p0 and sees p0 isn't found there",
        "ts": "1476996979.002431"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "I think that it doesn't impact heavily the size of the block , as long as we have like, up to hundreds of peers",
        "ts": "1476997014.002432"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Is it the hash of the set of peers, or a set of hashes of the peers?",
        "ts": "1476997046.002433"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "the set of hashes",
        "ts": "1476997051.002434"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "else it doesn't give you any information",
        "ts": "1476997060.002435"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Why not simply embed it in the configuration and not in every block?",
        "ts": "1476997076.002436"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "because you can't send the new configuration to p1 in time",
        "ts": "1476997095.002437"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Right, I thought you were referring to a different problem. ",
        "ts": "1476997106.002438"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "p1 might *also* get the block that is created after T, from a fellow peer, who did get the configuration but sent it to p1 as it's allowed to",
        "edited": {
            "user": "U0ZJZBJLF",
            "ts": "1476997158.000000"
        },
        "ts": "1476997143.002439"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I'm not sure I follow:\n\n&gt; because you can't send the new configuration to p1 in time\n\nThe configuration is in a block? You must have it before you can send future blocks",
        "ts": "1476997206.002441"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Exactly. In your original problem statement, didn't you refer to a node that comes back online and doesn't know whether it can reach out to another peer for a specific channel?",
        "ts": "1476997236.002442"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "you're saying that if p1 got a block that is created after time T, is must have gotten that configuration block?",
        "ts": "1476997286.002443"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Yes. ",
        "ts": "1476997295.002444"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "that's only if it gets it from the consensus, what if the state replication isn't in-order?",
        "ts": "1476997314.002445"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "and p1 got it from a peer p2 ?",
        "ts": "1476997322.002446"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "oh",
        "ts": "1476997328.002447"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "hmmm... I see",
        "ts": "1476997342.002448"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "all blocks are part of the same chain",
        "ts": "1476997348.002449"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "so it can't commit the block until it \"committed\" the configuration block, right?",
        "edited": {
            "user": "U0ZJZBJLF",
            "ts": "1476997389.000000"
        },
        "ts": "1476997357.002450"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Unless everything is ordered and verified in a chain you don't act. ",
        "ts": "1476997359.002451"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Exactly.  This vastly simplifies state transfer, as you play state forward, rather than backwards then forwards.",
        "ts": "1476997421.002453"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "yep. Thanks for the clarifications!",
        "ts": "1476997456.002454"
    },
    {
        "type": "message",
        "user": "U0ZJZBJLF",
        "text": "carry on with kafka",
        "ts": "1476997461.002455"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "So, we left it here: <https:\/\/hyperledgerproject.slack.com\/archives\/fabric-consensus-dev\/p1476995407002343>",
        "attachments": [
            {
                "from_url": "https:\/\/hyperledgerproject.slack.com\/archives\/fabric-consensus-dev\/p1476995407002343",
                "fallback": "[October 20th, 2016 1:30 PM] jyellick: And who's responsibility is it to put the block onto the block channel?",
                "ts": "1476995407.002343",
                "author_subname": "jyellick",
                "channel_id": "C0Z4NBUN6",
                "channel_name": "fabric-consensus-dev",
                "is_msg_unfurl": true,
                "text": "And who's responsibility is it to put the block onto the block channel?",
                "author_name": "Jason Yellick",
                "author_link": "https:\/\/hyperledgerproject.slack.com\/team\/jyellick",
                "author_icon": "https:\/\/secure.gravatar.com\/avatar\/80fccad690b283483c3b5418b8b82b5b.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2F272a%2Fimg%2Favatars%2Fava_0026-48.png",
                "mrkdwn_in": [
                    "text"
                ],
                "id": 1,
                "footer": "Posted in #fabric-consensus-dev"
            }
        ],
        "ts": "1476997517.002456"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "And my response to that is --",
        "ts": "1476997544.002458"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "This is exactly why I wrote: <https:\/\/hyperledgerproject.slack.com\/archives\/fabric-consensus-dev\/p1476994690002325>",
        "attachments": [
            {
                "from_url": "https:\/\/hyperledgerproject.slack.com\/archives\/fabric-consensus-dev\/p1476994690002325",
                "fallback": "[October 20th, 2016 1:18 PM] kostas: The problem is that whereas multiple \"let's cut for block X\" messages in partition A are harmless, that's not the case for partition B.",
                "ts": "1476994690.002325",
                "author_subname": "kostas",
                "channel_id": "C0Z4NBUN6",
                "channel_name": "fabric-consensus-dev",
                "is_msg_unfurl": true,
                "text": "The problem is that whereas multiple \"let's cut for block X\" messages in partition A are harmless, that's not the case for partition B.",
                "author_name": "Kostas Christidis",
                "author_link": "https:\/\/hyperledgerproject.slack.com\/team\/kostas",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2016-04-05\/31983107923_80db5353e9278df980c7_48.png",
                "mrkdwn_in": [
                    "text"
                ],
                "id": 1,
                "footer": "Posted in #fabric-consensus-dev"
            }
        ],
        "ts": "1476997552.002459"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "And why I'm thinking that a raw ledger (as to your original suggestion) might be inevitable.",
        "ts": "1476997576.002461"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Okay, now I'm following you",
        "ts": "1476997629.002462"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "So, the reason why I reversed position on the raw ledger, is that in order to maintain a raw ledger, every shim must maintain a copy of every blockchain.  So whereas Kafka allows you to take 20 kafka nodes to spread out 10k partitions (at maybe 1000 partitions per broker), this would force the shims to maintain 10k chains, regardless.",
        "ts": "1476997751.002463"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "Good point.",
        "ts": "1476997782.002464"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "I think inevitably we'll get down to option 3 (maybe with a different ZK ensemble) as a clearly elected leader could save us from all of these problems. Let's try to approach it like option 4 for now, and see if some simple logic from the shim side (\"the shim who sent the first 'cut block' is supposed to put the block?\" that can also fail in a ton of ways, e.g. that shim can crash but that's the example of logic that I'm talking about) can take us all the way there.",
        "edited": {
            "user": "U0XQ35CDD",
            "ts": "1476997982.000000"
        },
        "ts": "1476997964.002465"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "I was typing something similar.  Option (3) seems somewhat inevitable.  Or rather, each channel needs a leader to do the actual block cutting, and leveraging ZK seems like a natural fit.  We can definitely use 4 to mimic some leader election, and that may be the path of least resistance for now, but, I would be wary of sinking too much effort into hacking on a 'leader election over Kafka', when there are obviously purpose built tools (like ZK) out there for just such a thing.",
        "edited": {
            "user": "U0XPR4NP4",
            "ts": "1476998217.000000"
        },
        "ts": "1476998197.002467"
    },
    {
        "type": "message",
        "user": "U2BGFAHC7",
        "text": "Why not just raft?",
        "ts": "1476998275.002469"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "<@U2BGFAHC7> RAFT would certainly be a solution, or etcd, or any of these other canned consensus options.  But, since we are working with Kafka and must have a ZK deployment already, it seems like a good option.",
        "ts": "1476998330.002470"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "<@U2BGFAHC7> Option 3 would entail etcd (so Raft), or a ZK ensemble.",
        "ts": "1476998349.002471"
    },
    {
        "type": "message",
        "user": "U2BGFAHC7",
        "text": "Thanks for the answer :slightly_smiling_face:",
        "ts": "1476998369.002472"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "Sure thing",
        "ts": "1476998404.002473"
    },
    {
        "type": "message",
        "subtype": "pinned_item",
        "user": "U0XQ35CDD",
        "item_type": "C",
        "attachments": [
            {
                "fallback": "[October 18th, 2016 9:04 AM] kostas: I looked at the relevant KIPs, etc. and I think my options come down to these.",
                "ts": "1476806651.002202",
                "author_subname": "kostas",
                "channel_id": "C0Z4NBUN6",
                "channel_name": "fabric-consensus-dev",
                "is_msg_unfurl": true,
                "text": "I looked at the relevant KIPs, etc. and I think my options come down to these.",
                "author_name": "Kostas Christidis",
                "author_link": "https:\/\/hyperledgerproject.slack.com\/team\/kostas",
                "author_icon": "https:\/\/avatars.slack-edge.com\/2016-04-05\/31983107923_80db5353e9278df980c7_48.png",
                "mrkdwn_in": [
                    "text"
                ]
            }
        ],
        "text": "<@U0XQ35CDD|kostas> pinned a message to this channel.",
        "ts": "1476998512.002474"
    },
    {
        "type": "message",
        "user": "U0XPR4NP4",
        "text": "<@U0XQ35CDD> So I am thinking maybe the common components across Kafka\/Solo (and ultimately SBFT), is going to be the incoming broadcast filtering, block cutting based on some stream of messages (not only the incoming broadcast messages), and then block stream consumption (for reconfiguration)",
        "ts": "1476998567.002475"
    },
    {
        "type": "message",
        "user": "U0XQ35CDD",
        "text": "This sounds right to me.",
        "ts": "1476998729.002476"
    },
    {
        "user": "U2NPXKPQ8",
        "text": "<@U2NPXKPQ8|qq> has joined the channel",
        "type": "message",
        "subtype": "channel_join",
        "ts": "1477014067.002477"
    }
]