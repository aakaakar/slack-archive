[{"user":"U0U2AJURZ","type":"message","subtype":"channel_join","text":"<@U0U2AJURZ|renat-altoros> has joined the channel","ts":"1460741565.000002"},{"user":"U0U2AJURZ","purpose":"Scalability and performance engineering of Hyperledger:\r\n- performance (parameters of workloads such as latency, throughput, persistence)\r\n- workload generator tools\r\n- benchmark results.","type":"message","subtype":"channel_purpose","text":"<@U0U2AJURZ|renat-altoros> set the channel purpose: Scalability and performance engineering of Hyperledger:\r\n- performance (parameters of workloads such as latency, throughput, persistence)\r\n- workload generator tools\r\n- benchmark results.","ts":"1460741567.000003"},{"user":"U0NCW1DPX","type":"message","subtype":"channel_join","text":"<@U0NCW1DPX|gengjh> has joined the channel","ts":"1460789074.000002"},{"user":"U11BP64LD","type":"message","subtype":"channel_join","text":"<@U11BP64LD|nathonline> has joined the channel","ts":"1460916644.000002"},{"user":"U10UX43K6","type":"message","subtype":"channel_join","text":"<@U10UX43K6|nicholas> has joined the channel","ts":"1460985511.000002"},{"user":"U0P75RFT4","type":"message","subtype":"channel_join","text":"<@U0P75RFT4|tim.blankers> has joined the channel","ts":"1460989347.000003"},{"user":"U117F4B6D","type":"message","subtype":"channel_join","text":"<@U117F4B6D|jean.safar> has joined the channel","ts":"1461074611.000004"},{"user":"U12BZTSM8","type":"message","subtype":"channel_join","text":"<@U12BZTSM8|mowntan> has joined the channel","ts":"1461179737.000005"},{"user":"U0J5URUJU","type":"message","subtype":"channel_join","text":"<@U0J5URUJU|nycnewman> has joined the channel","ts":"1461202506.000006"},{"user":"U126PEMNH","type":"message","subtype":"channel_join","text":"<@U126PEMNH|harshal> has joined the channel","ts":"1461256106.000007"},{"user":"U137A6LBE","type":"message","subtype":"channel_join","text":"<@U137A6LBE|latone> has joined the channel","ts":"1461458377.000008"},{"user":"U139XHJCB","type":"message","subtype":"channel_join","text":"<@U139XHJCB|aaren> has joined the channel","ts":"1461567061.000009"},{"user":"U0ZR63HLK","type":"message","subtype":"channel_join","text":"<@U0ZR63HLK|adc> has joined the channel","ts":"1461575821.000010"},{"user":"U13DAL5V5","type":"message","subtype":"channel_join","text":"<@U13DAL5V5|wimtobback> has joined the channel","ts":"1461584353.000011"},{"user":"U13JUH485","type":"message","subtype":"channel_join","text":"<@U13JUH485|fabio> has joined the channel","ts":"1461617720.000012"},{"user":"U0PKMSYKG","type":"message","subtype":"channel_join","text":"<@U0PKMSYKG|j3ffyang> has joined the channel","ts":"1461633108.000013"},{"user":"U0N1D1UAE","type":"message","subtype":"channel_join","text":"<@U0N1D1UAE|bcbrock> has joined the channel","ts":"1461771629.000014"},{"user":"U10U36Y4F","type":"message","subtype":"channel_join","text":"<@U10U36Y4F|hmchen> has joined the channel","ts":"1461797148.000015"},{"user":"U0N1K6Z0X","type":"message","subtype":"channel_join","text":"<@U0N1K6Z0X|georglink> has joined the channel","ts":"1461852127.000016"},{"user":"U14KBK932","type":"message","subtype":"channel_join","text":"<@U14KBK932|louie.stavrakos> has joined the channel","ts":"1461864957.000017"},{"user":"U0V2F6PU4","type":"message","subtype":"channel_join","text":"<@U0V2F6PU4|jeremyeder> has joined the channel","ts":"1462301921.000018"},{"user":"U163J7MRT","type":"message","subtype":"channel_join","text":"<@U163J7MRT|hill> has joined the channel","ts":"1462372304.000019"},{"user":"U0ZMB7ZEJ","type":"message","subtype":"channel_join","text":"<@U0ZMB7ZEJ|jatinderbali> has joined the channel","ts":"1462625995.000020"},{"user":"U173QDB0W","type":"message","subtype":"channel_join","text":"<@U173QDB0W|pablofullana> has joined the channel","ts":"1462745646.000021"},{"user":"U16FB85U6","type":"message","subtype":"channel_join","text":"<@U16FB85U6|yiseul> has joined the channel","ts":"1462961134.000022"},{"user":"U0Y14MWA2","type":"message","subtype":"channel_join","text":"<@U0Y14MWA2|vukolic> has joined the channel","ts":"1462970682.000023"},{"user":"U1802P5D3","type":"message","subtype":"channel_join","text":"<@U1802P5D3|jianzhang98> has joined the channel","ts":"1463262744.000024"},{"user":"U196VQF1N","type":"message","subtype":"channel_join","text":"<@U196VQF1N|vladimir.starostenkov> has joined the channel","ts":"1463407266.000025"},{"user":"U1A5P979S","type":"message","subtype":"channel_join","text":"<@U1A5P979S|v.thirugnanam> has joined the channel","ts":"1463695779.000026"},{"user":"U10Q62R8X","type":"message","subtype":"channel_join","text":"<@U10Q62R8X|vpaprots> has joined the channel","ts":"1463707864.000027"},{"user":"U0Z41KY5V","type":"message","subtype":"channel_join","text":"<@U0Z41KY5V|baohua> has joined the channel","ts":"1464312331.000028"},{"type":"message","user":"U0Z41KY5V","text":"hi, my team is working on mearsuring the performance of blockchain cluster, do we already have some benchmark or tools? Do not wanna reinvent wheels :slightly_smiling_face:","ts":"1464312395.000029"},{"type":"message","user":"U0NCW1DPX","text":"<@U0Z41KY5V>: try this pls: <https:\/\/github.com\/hyperledger\/fabric\/tree\/master\/tools\/busywork>","attachments":[{"service_name":"GitHub","title":"hyperledger\/fabric","title_link":"https:\/\/github.com\/hyperledger\/fabric\/tree\/master\/tools\/busywork","text":"fabric - Fabric is a blockchain project in Incubation proposed to the community and documented at <https:\/\/goo.gl\/RYQZ5N>. Information on what Incubation entails can be found in the Hyperledger Proj...","fallback":"GitHub: hyperledger\/fabric","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/7657900?v=3&s=400","from_url":"https:\/\/github.com\/hyperledger\/fabric\/tree\/master\/tools\/busywork","thumb_width":142,"thumb_height":142,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1464317297.000030"},{"type":"message","user":"U0Z41KY5V","text":"yes, i got it, thanks gengjh!","ts":"1464317330.000032"},{"user":"U14NC480K","type":"message","subtype":"channel_join","text":"<@U14NC480K|charles-cai> has joined the channel","ts":"1464355953.000033"},{"user":"U142E5N0P","type":"message","subtype":"channel_join","text":"<@U142E5N0P|yingfeng> has joined the channel","ts":"1464771718.000034"},{"type":"message","user":"U0N1D1UAE","text":"<!channel> I have created a Wiki page \u201cGo Performance Portal\u201d and seeded the page with 3 articles: <https:\/\/github.com\/hyperledger\/fabric\/wiki\/Go-Performance-Portal>","attachments":[{"service_name":"GitHub","title":"hyperledger\/fabric","title_link":"https:\/\/github.com\/hyperledger\/fabric\/wiki\/Go-Performance-Portal","text":"fabric - Fabric is a blockchain project in Incubation proposed to the community and documented at <https:\/\/goo.gl\/RYQZ5N>. Information on what Incubation entails can be found in the Hyperledger Proj...","fallback":"GitHub: hyperledger\/fabric","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/7657900?v=3&s=400","from_url":"https:\/\/github.com\/hyperledger\/fabric\/wiki\/Go-Performance-Portal","thumb_width":142,"thumb_height":142,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"edited":{"user":"U0N1D1UAE","ts":"1464847415.000000"},"ts":"1464847374.000035"},{"user":"U1DFU0M32","type":"message","subtype":"channel_join","text":"<@U1DFU0M32|chenhua> has joined the channel","ts":"1464886374.000038"},{"user":"U1E795PLG","type":"message","subtype":"channel_join","text":"<@U1E795PLG|starsheriff> has joined the channel","ts":"1465209449.000002"},{"user":"U1EEGQARJ","type":"message","subtype":"channel_join","text":"<@U1EEGQARJ|philippe> has joined the channel","ts":"1465226694.000003"},{"user":"U11NUTP4L","type":"message","subtype":"channel_join","text":"<@U11NUTP4L|srirama_sharma> has joined the channel","ts":"1465365172.000004"},{"user":"U16NDNH08","type":"message","subtype":"channel_join","text":"<@U16NDNH08|crow15> has joined the channel","ts":"1465402917.000005"},{"user":"U1F9YEMGW","type":"message","subtype":"channel_join","text":"<@U1F9YEMGW|horii> has joined the channel","ts":"1465434534.000006"},{"user":"U1GN670VD","type":"message","subtype":"channel_join","text":"<@U1GN670VD|thiruworkspace> has joined the channel","ts":"1465907325.000002"},{"user":"U0UGH3X7X","type":"message","subtype":"channel_join","text":"<@U0UGH3X7X|tuand> has joined the channel","ts":"1465922354.000003"},{"user":"U0XR6J961","type":"message","subtype":"channel_join","text":"<@U0XR6J961|simon> has joined the channel","ts":"1465922382.000004"},{"type":"message","user":"U0XR6J961","text":"hi","ts":"1465922387.000005"},{"user":"U0XV1HDL3","type":"message","subtype":"channel_join","text":"<@U0XV1HDL3|cca> has joined the channel","ts":"1465922421.000006"},{"type":"message","user":"U0XR6J961","text":"i can now prove that the poor invoke performance we observe is exactly because of what i hypothesized before:  go routine scheduling issues","ts":"1465922444.000007"},{"type":"message","user":"U0XR6J961","text":"specifically, if a goroutine is blocked waiting on file IO (socket, connection to chaincode container), it is not guaranteed to be scheduled preferentially when the IO unblocks","ts":"1465922497.000008"},{"type":"message","user":"U0XR6J961","text":"it is easy to observe when you first just use two goroutines that bounce execution between themselves, using a unix pipe.  The latency I observe on my system is on the order of 10us.","ts":"1465922552.000009"},{"type":"message","user":"U0XR6J961","text":"as soon as i add other goroutines that do compute and IO, the latency of the original goroutine pair jumps to order 10ms.","ts":"1465922588.000010"},{"type":"message","user":"U0XR6J961","text":"which happens to be ~ the 100tps performance we observe","ts":"1465922607.000011"},{"type":"message","user":"U0XR6J961","text":"demo: <https:\/\/github.com\/corecode\/goroutine-latency>","attachments":[{"service_name":"GitHub","title":"corecode\/goroutine-latency","title_link":"https:\/\/github.com\/corecode\/goroutine-latency","text":"Contribute to goroutine-latency development by creating an account on GitHub.","fallback":"GitHub: corecode\/goroutine-latency","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/177979?v=3&s=400","from_url":"https:\/\/github.com\/corecode\/goroutine-latency","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1465922905.000012"},{"type":"message","user":"U0XR6J961","text":"observe how the latency profile of benchPipe increases significantly once activity &gt; 0","ts":"1465922944.000014"},{"type":"message","user":"U0XR6J961","text":"but other benchmarks don't","ts":"1465922956.000015"},{"type":"message","user":"U0XR6J961","text":"i'd appreciate if somebody could cross-check this and tell me where i am wrong","ts":"1465922983.000016"},{"user":"U0XPR4NP4","type":"message","subtype":"channel_join","text":"<@U0XPR4NP4|jyellick> has joined the channel","ts":"1465934537.000017"},{"user":"U0KPFAZNF","type":"message","subtype":"channel_join","text":"<@U0KPFAZNF|ghaskins> has joined the channel","ts":"1465942828.000018"},{"user":"U12452RAP","type":"message","subtype":"channel_join","text":"<@U12452RAP|grapebaba> has joined the channel","ts":"1465958078.000019"},{"user":"U1CK6522F","type":"message","subtype":"channel_join","text":"<@U1CK6522F|zuowang> has joined the channel","ts":"1465972492.000020"},{"user":"U0ULK2JPP","type":"message","subtype":"channel_join","text":"<@U0ULK2JPP|muralisr> has joined the channel","ts":"1466023271.000021"},{"user":"U0XQ35CDD","type":"message","subtype":"channel_join","text":"<@U0XQ35CDD|kostas> has joined the channel","ts":"1466023374.000022"},{"user":"U0KM61BCP","type":"message","subtype":"channel_join","text":"<@U0KM61BCP|cbf> has joined the channel","ts":"1466025843.000023"},{"type":"message","subtype":"file_share","text":"<@U1CK6522F|zuowang> uploaded a file: <https:\/\/hyperledgerproject.slack.com\/files\/zuowang\/F1HBQS62E\/fabric.svg|fabric.svg>","file":{"id":"F1HBQS62E","created":1466036956,"timestamp":1466036956,"name":"fabric.svg","title":"fabric.svg","mimetype":"image\/svg+xml","filetype":"svg","pretty_type":"SVG","user":"U1CK6522F","editable":false,"size":111061,"mode":"hosted","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https:\/\/files.slack.com\/files-pri\/T0J024XGA-F1HBQS62E\/fabric.svg?t=xoxe-18002167554-139099126023-137701436192-e599afc92e","url_private_download":"https:\/\/files.slack.com\/files-pri\/T0J024XGA-F1HBQS62E\/download\/fabric.svg?t=xoxe-18002167554-139099126023-137701436192-e599afc92e","permalink":"https:\/\/hyperledgerproject.slack.com\/files\/zuowang\/F1HBQS62E\/fabric.svg","permalink_public":"https:\/\/slack-files.com\/T0J024XGA-F1HBQS62E-9d4be39e88","channels":["C113WK2A1"],"groups":[],"ims":[],"comments_count":0},"user":"U1CK6522F","upload":true,"display_as_bot":false,"username":"<@U1CK6522F|zuowang>","bot_id":null,"ts":"1466036956.000024"},{"type":"message","user":"U1CK6522F","text":"I got a profile of fabric. runtime._ExternalCost took 36.88% of cpu. What was that native code doing, and why they took so much time?","ts":"1466037177.000025"},{"user":"U0XRC0KLH","type":"message","subtype":"channel_join","text":"<@U0XRC0KLH|chetsky> has joined the channel","ts":"1466049222.000026"},{"type":"message","user":"U0XR6J961","text":"zuowang: what does that chart show?","ts":"1466064233.000027"},{"type":"message","user":"U1CK6522F","text":"It shows a profile of peer node using \"go tool pprof <http:\/\/172.17.0.2:6060\/debug\/pprof\/profile>\" while there is one thread invoking the chaincode busily.","ts":"1466066591.000028"},{"type":"message","user":"U0XR6J961","text":"okay","ts":"1466067047.000029"},{"type":"message","user":"U0XR6J961","text":"zuowang: but it seems that it is mostly idle","ts":"1466067067.000030"},{"user":"U0Z541B3P","type":"message","subtype":"channel_join","text":"<@U0Z541B3P|manish-sethi> has joined the channel","ts":"1466080792.000031"},{"user":"U126PEMNH","type":"message","subtype":"channel_leave","text":"<@U126PEMNH|harshal> has left the channel","ts":"1466094172.000032"},{"user":"U1GNP6E7N","type":"message","subtype":"channel_join","text":"<@U1GNP6E7N|pax> has joined the channel","ts":"1466122974.000033"},{"user":"U0PV6MUD6","type":"message","subtype":"channel_join","text":"<@U0PV6MUD6|sbrakev> has joined the channel","ts":"1466162158.000034"},{"user":"U1HR1RWMR","type":"message","subtype":"channel_join","text":"<@U1HR1RWMR|illya13> has joined the channel","ts":"1466165235.000035"},{"user":"U1AU8DRQR","type":"message","subtype":"channel_join","text":"<@U1AU8DRQR|hgabor> has joined the channel","ts":"1466168089.000036"},{"type":"message","user":"U1AU8DRQR","text":"Can fabric peer be profiled more throughly? I mean more info about external code part","ts":"1466173561.000037"},{"type":"message","user":"U1AU8DRQR","text":"I ve read on some page that external code only means calls to dynamically linked libs","ts":"1466173607.000038"},{"type":"message","user":"U0XR6J961","text":"what makes you think that this is even relevant?","ts":"1466173719.000039"},{"type":"message","user":"U1AU8DRQR","text":"I'm not sure but I got the same results ","ts":"1466176628.000040"},{"type":"message","user":"U1AU8DRQR","text":"I just want to do some more precise measurements ","ts":"1466176710.000041"},{"user":"U1115UL9W","type":"message","subtype":"channel_join","text":"<@U1115UL9W|takakir> has joined the channel","ts":"1466305635.000042"},{"user":"U0ZJZBJLF","type":"message","subtype":"channel_join","text":"<@U0ZJZBJLF|yacovm> has joined the channel","ts":"1466324065.000043"},{"type":"message","user":"U0XR6J961","text":"hgabor: did you look at the absolute time spent?","ts":"1466405961.000044"},{"type":"message","user":"U1AU8DRQR","text":"To be honest I didn't ","ts":"1466406277.000045"},{"type":"message","user":"U1AU8DRQR","text":"Do you mean the absolute time that was spent busy? Or?","ts":"1466406313.000046"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1466406486.000047"},{"type":"message","user":"U1AU8DRQR","text":"this is not an official measurement just some kind of experiment but I get lines like this:\n     2.74s 36.53% 74.00%      2.74s 36.53%  runtime._ExternalCode","ts":"1466406752.000048"},{"type":"message","user":"U1AU8DRQR","text":"where should that busily spent time amount be?","ts":"1466406792.000049"},{"type":"message","user":"U1AU8DRQR","text":"is it possible to get more specific results? to get some kind of breakdown from that external code call","ts":"1466407594.000050"},{"type":"message","user":"U0XR6J961","text":"i'd guess rocksdb","ts":"1466407942.000051"},{"type":"message","user":"U0XR6J961","text":"2.74s out of how many seconds?","ts":"1466407956.000052"},{"type":"message","user":"U1AU8DRQR","text":"I ve found it, total is 7,5","ts":"1466408243.000053"},{"type":"message","user":"U0XR6J961","text":"what's your total runtime","ts":"1466408293.000054"},{"type":"message","user":"U0XR6J961","text":"30s?","ts":"1466408303.000055"},{"type":"message","user":"U1AU8DRQR","text":"I only have the results from \"top10\", the profile file itself was overwritten because I experimented with other options for the profiler","ts":"1466408422.000056"},{"type":"message","user":"U1AU8DRQR","text":"but lets say it was 5 minutes","ts":"1466408442.000057"},{"type":"message","user":"U1AU8DRQR","text":"I sent 10K TXs to the system","ts":"1466408475.000058"},{"type":"message","user":"U1AU8DRQR","text":"and created a profile from that","ts":"1466408487.000059"},{"type":"message","user":"U0XR6J961","text":"&lt;3s for 5min runtime is negligible","ts":"1466408509.000060"},{"type":"message","user":"U1AU8DRQR","text":"what does this \"6.77s of 7.50s total (90.27%)\" mean in the output of pprof?","ts":"1466408594.000061"},{"type":"message","user":"U1AU8DRQR","text":"I can show you some lines from that output:","ts":"1466408609.000062"},{"type":"message","user":"U1AU8DRQR","text":"(pprof) top10\n6.77s of 7.50s total (90.27%)\nDropped 171 nodes (cum &lt;= 0.04s)\nShowing top 10 nodes out of 106 (cum &gt;= 0.05s)\n      flat  flat%   sum%        cum   cum%\n     2.81s 37.47% 37.47%      2.91s 38.80%  syscall.Syscall\n     2.74s 36.53% 74.00%      2.74s 36.53%  runtime._ExternalCode\n     0.59s  7.87% 81.87%      0.59s  7.87%  runtime.futex","ts":"1466408632.000063"},{"type":"message","user":"U1AU8DRQR","text":"so what does that 6.77s of 7.50 mean? does it mean that the top10 calls used 7.50s from the total runtime?","ts":"1466408732.000064"},{"type":"message","user":"U1AU8DRQR","text":"if yes that is a really small amount","ts":"1466408792.000065"},{"type":"message","user":"U1AU8DRQR","text":"<@U0XR6J961>: how can I get the full runtime from the profiling log?","ts":"1466410744.000066"},{"type":"message","user":"U1CK6522F","text":"<@U0XR6J961>: \nQ1: I found there is always one goroutine do the commit work.  Is this the reason why my cpu time is less than 200%(I got 32 cores)? \nQ2: I saw this function <http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).recvCommit|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).recvCommit> took 9.67% of my cpu time. I was running a quite simple chaincode: chaincode_example02. Does that mean the perfmance would be much worse when I add more logicals to chaincode?\nThank you very much!\ngoroutine 13 [runnable]:\nreflect.Value.NumField(0xd50420, 0xc859cbe350, 0x199, 0xc8b9c40aee)\n\t\/opt\/go\/src\/reflect\/value.go:1152\nreflect.deepValueEqual(0xd50420, 0xc859cbe350, 0x199, 0xd50420, 0xc886b16bc0, 0x199, 0xc8b9c415d8, 0x3, 0xc8c94d6800)\n\t\/opt\/go\/src\/reflect\/deepequal.go:96 +0x12e6\nreflect.deepValueEqual(0xd821a0, 0xc8802c1080, 0x196, 0xd821a0, 0xc8be7ba440, 0x196, 0xc8b9c415d8, 0x2, 0x0)\n\t\/opt\/go\/src\/reflect\/deepequal.go:94 +0xfac\nreflect.deepValueEqual(0xd8b540, 0xc8802c1080, 0x199, 0xd8b540, 0xc8be7ba440, 0x199, 0xc8b9c415d8, 0x1, 0x7ff8c6ffa000)\n\t\/opt\/go\/src\/reflect\/deepequal.go:97 +0x140f\nreflect.deepValueEqual(0xd96c40, 0xc8802c1080, 0x16, 0xd96c40, 0xc8be7ba440, 0x16, 0xc8b9c415d8, 0x0, 0x7ff8c6ffa000)\n\t\/opt\/go\/src\/reflect\/deepequal.go:94 +0xfac\nreflect.DeepEqual(0xd96c40, 0xc8802c1080, 0xd96c40, 0xc8be7ba440, 0xc8c92fc600)\n\t\/opt\/go\/src\/reflect\/deepequal.go:185 +0x253\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*obcBatch).execute(0xc820270840|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*obcBatch).execute(0xc820270840>, 0x156, 0xc8a914e480, 0x208, 0x208)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/obc-batch.go:214 +0x8ec\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).executeOne(0xc8202a6000|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).executeOne(0xc8202a6000>, 0x0, 0x156, 0xc886b16a00)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/pbft-core.go:978 +0x77f\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).executeOutstanding(0xc8202a6000)|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).executeOutstanding(0xc8202a6000)>\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/pbft-core.go:933 +0x333\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).recvCommit(0xc8202a6000|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).recvCommit(0xc8202a6000>, 0xc886968a50, 0x0, 0x0)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/pbft-core.go:868 +0xcf0\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).ProcessEvent(0xc8202a6000|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*pbftCore).ProcessEvent(0xc8202a6000>, 0xd7b8a0, 0xc886968a50, 0x0, 0x0)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/pbft-core.go:338 +0x1559\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*obcBatch).ProcessEvent(0xc820270840|github.com\/hyperledger\/fabric\/consensus\/obcpbft.(*obcBatch).ProcessEvent(0xc820270840>, 0xd7b8a0, 0xc886968a50, 0x0, 0x0)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/obc-batch.go:383 +0x599\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.SendEvent(0x7ff8c6ffcea0|github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.SendEvent(0x7ff8c6ffcea0>, 0xc820270840, 0xd48fc0, 0xc8a5a59c90)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events\/events.go:113 +0x45\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.(*managerImpl).Inject(0xc820279720|github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.(*managerImpl).Inject(0xc820279720>, 0xd48fc0, 0xc8a5a59c90)\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events\/events.go:123 +0x4f\n<http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.(*managerImpl).eventLoop(0xc820279720)|github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.(*managerImpl).eventLoop(0xc820279720)>\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events\/events.go:132 +0xdb\ncreated by <http:\/\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.(*managerImpl).Start|github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events.(*managerImpl).Start>\n\t\/opt\/gopath\/src\/github.com\/hyperledger\/fabric\/consensus\/obcpbft\/events\/events.go:100 +0x35","ts":"1466414365.000067"},{"type":"message","user":"U1CK6522F","text":"<@U1AU8DRQR>  <@U0XR6J961> The profile I got is with 4 validator node on vagrant on my single windows machine. The part for runtime._ExternalCode is unexpectly high. But when I profile fabric on a cluster of 4 node. The result is make much sense.","ts":"1466414541.000068"},{"type":"message","subtype":"file_share","text":"<@U1CK6522F|zuowang> uploaded a file: <https:\/\/hyperledgerproject.slack.com\/files\/zuowang\/F1JAULGFM\/callgrind.benchmark|callgrind.benchmark>","file":{"id":"F1JAULGFM","created":1466414600,"timestamp":1466414600,"name":"callgrind.benchmark","title":"callgrind.benchmark","mimetype":"text\/plain","filetype":"text","pretty_type":"Plain Text","user":"U1CK6522F","editable":true,"size":81204,"mode":"snippet","is_external":false,"external_type":"","is_public":true,"public_url_shared":false,"display_as_bot":false,"username":"","url_private":"https:\/\/files.slack.com\/files-pri\/T0J024XGA-F1JAULGFM\/callgrind.benchmark?t=xoxe-18002167554-139099126023-137701436192-e599afc92e","url_private_download":"https:\/\/files.slack.com\/files-pri\/T0J024XGA-F1JAULGFM\/download\/callgrind.benchmark?t=xoxe-18002167554-139099126023-137701436192-e599afc92e","permalink":"https:\/\/hyperledgerproject.slack.com\/files\/zuowang\/F1JAULGFM\/callgrind.benchmark","permalink_public":"https:\/\/slack-files.com\/T0J024XGA-F1JAULGFM-949ea6b601","edit_link":"https:\/\/hyperledgerproject.slack.com\/files\/zuowang\/F1JAULGFM\/callgrind.benchmark\/edit","preview":"events: cpu(ms)\nfl=\nfn=(1) syscall.Syscall\n0 9990\ncfl=","preview_highlight":"<div class=\"CodeMirror cm-s-default CodeMirrorServer\" oncopy=\"if(event.clipboardData){event.clipboardData.setData('text\/plain',window.getSelection().toString().replace(\/\\u200b\/g,''));event.preventDefault();event.stopPropagation();}\">\n<div class=\"CodeMirror-code\">\n<div><pre>events: cpu(ms)<\/pre><\/div>\n<div><pre>fl=<\/pre><\/div>\n<div><pre>fn=(1) syscall.Syscall<\/pre><\/div>\n<div><pre>0 9990<\/pre><\/div>\n<div><pre>cfl=<\/pre><\/div>\n<\/div>\n<\/div>\n","lines":8318,"lines_more":8313,"preview_is_truncated":true,"channels":["C113WK2A1"],"groups":[],"ims":[],"comments_count":0},"user":"U1CK6522F","upload":true,"display_as_bot":false,"username":"<@U1CK6522F|zuowang>","bot_id":null,"ts":"1466414600.000069"},{"type":"message","user":"U1CK6522F","text":"<@U1AU8DRQR>  <@U0XR6J961> This is the profile I get from a cluster of 4 nodes. open it with kcachegrind or qcachegrind on windows.","ts":"1466414691.000070"},{"type":"message","user":"U0XR6J961","text":"hi zuowang","ts":"1466415966.000071"},{"type":"message","user":"U0XR6J961","text":"are you still around?","ts":"1466415972.000072"},{"type":"message","user":"U1CK6522F","text":"<@U0XR6J961> yes!","ts":"1466421050.000073"},{"type":"message","user":"U142E5N0P","text":"`noops` adopts 200 channels to accept for transaction requests, and the average `invoke` TPS for `noops` on single peer node is around 700 per second, however, there's only one channel for `pbft`, and the average `invoke` TPS is only 15 per second or so.  \nDoes there exist further plan to improve the performance as much as possible?  According to the target, which claims to achieve 100K given 15 peer nodes, even if the performance could be linearly scalable, single peer node has to reach at least 7000 per second.","ts":"1466425887.000074"},{"type":"message","user":"U0XR6J961","text":"yingfeng: do you see also 700 requests being committed per second?","ts":"1466426495.000075"},{"type":"message","user":"U0XR6J961","text":"do you also see 700 queries per second?","ts":"1466426511.000076"},{"type":"message","user":"U0XR6J961","text":"<@U142E5N0P>: that 100k target is completely unrealistic","ts":"1466426532.000077"},{"type":"message","user":"U0XR6J961","text":"performance is not scalable at all","ts":"1466426548.000078"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>: what is the aim of the performance for a single peer node?","ts":"1466428979.000079"},{"type":"message","user":"U0XR6J961","text":"as fast as possible","ts":"1466429161.000080"},{"type":"message","user":"U0XR6J961","text":":slightly_smiling_face:","ts":"1466429164.000081"},{"type":"message","user":"U0XR6J961","text":"ideally at network line speed","ts":"1466429181.000082"},{"type":"message","user":"U0XR6J961","text":"but right now this totally doesn't work","ts":"1466429193.000083"},{"user":"U18P24857","type":"message","subtype":"channel_join","text":"<@U18P24857|dongmingh> has joined the channel","ts":"1466458527.000084"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>  when `noops` is configured, the practical TPS is around 700 per peer node, and when jmeter is stopped, the CPU of peer node reduces to idle immediately, while when `pbft` is configured, there's an remarkable asynchronous behavior such that the peer node will keep CPU busy for a long time even if jmeter had been stopped long before.","ts":"1466470299.000085"},{"type":"message","user":"U0UGH3X7X","text":"But noops is a fake consensus protocol which is basically a passthrough. I don't think you can get valid data comparing noops and pbft. ","ts":"1466473358.000086"},{"type":"message","user":"U142E5N0P","text":"<@U0UGH3X7X>: I'm just going to find the reason why pbft has such a poor performance, as well as how and when fabric could reach a reasonable performance target","ts":"1466473623.000087"},{"type":"message","user":"U0XR6J961","text":"yingfeng: are you sure that all your requests are processed with noops?","ts":"1466504203.000088"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>: almost yes.  I sent query request at the same time and see that the result of the chaincode transaction has taken into effects with a much faster speed than `pbft`","ts":"1466505734.000089"},{"type":"message","user":"U0XR6J961","text":"very interesting.","ts":"1466505752.000090"},{"type":"message","user":"U0XR6J961","text":"how many nodes do you use?","ts":"1466505758.000091"},{"type":"message","user":"U142E5N0P","text":"4 nodes","ts":"1466505766.000092"},{"type":"message","user":"U0XR6J961","text":"can you increase the batchsize to 100 or 1000?","ts":"1466505801.000093"},{"type":"message","user":"U142E5N0P","text":"i tried before, but it has no differences","ts":"1466505882.000094"},{"type":"message","user":"U0XR6J961","text":"there was a fix recently","ts":"1466505890.000095"},{"type":"message","user":"U142E5N0P","text":"okay.","ts":"1466505905.000096"},{"type":"message","user":"U142E5N0P","text":"i also notice that within the eventLoop \n```\nfunc (em *managerImpl) eventLoop() {\n\tfor {\n\t\tselect {\n\t\tcase next := &lt;-em.events:\n\t\t\tem.Inject(next)\n\t\tcase &lt;-em.exit:\n\t\t\tlogger.Debug(\"eventLoop told to exit\")\n\t\t\treturn\n\t\t}\n\t}\n}\n\n```\nwhy not assign a goroutine to `Inject` ?","ts":"1466505982.000097"},{"type":"message","user":"U0XR6J961","text":"instead of?","ts":"1466506010.000098"},{"type":"message","user":"U142E5N0P","text":"the channel will block until the requests have been finished processing.","ts":"1466506011.000099"},{"type":"message","user":"U0XR6J961","text":"yes of course","ts":"1466506017.000100"},{"type":"message","user":"U0XR6J961","text":"that's the whole point","ts":"1466506023.000101"},{"type":"message","user":"U142E5N0P","text":"a general concurrent server works in this way: dispatch requests to a queue, and a threadpool is attached to serve as workers. when there's a request being sent, it's retrieved and sent to a worker thread immediately.   however, in the above design, the eventloop works in a sequential way","ts":"1466506127.000102"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1466506141.000103"},{"type":"message","user":"U0XR6J961","text":"of course","ts":"1466506144.000104"},{"type":"message","user":"U0XR6J961","text":"consensus is a serialization device","ts":"1466506153.000105"},{"type":"message","user":"U0XR6J961","text":"that's the whole idea - all requests need to be processed in the same order everywhere","ts":"1466506193.000106"},{"type":"message","user":"U142E5N0P","text":"but i remember i was asking a question that when concurrent requests come, fabric will treat them at random order","ts":"1466506336.000107"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1466506347.000108"},{"type":"message","user":"U0XR6J961","text":"because concurrent means there is no inherent order","ts":"1466506361.000109"},{"type":"message","user":"U0XR6J961","text":"then consensus works together to serialize them","ts":"1466506372.000110"},{"type":"message","user":"U142E5N0P","text":"got it","ts":"1466506400.000111"},{"type":"message","user":"U0XR6J961","text":"do you think that's the source of performance problems?","ts":"1466506418.000112"},{"type":"message","user":"U142E5N0P","text":"i feel so.  my CPU occupation has never exceeded for 200%","ts":"1466506492.000113"},{"type":"message","user":"U0XR6J961","text":"well of course not","ts":"1466506499.000114"},{"type":"message","user":"U0XR6J961","text":"the transactions need to be executed sequentially :slightly_smiling_face:","ts":"1466506513.000115"},{"type":"message","user":"U142E5N0P","text":"a sequential execution will lead to more time to wait","ts":"1466506524.000116"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1466506529.000117"},{"type":"message","user":"U0XR6J961","text":"i don't think that noops will produce more cpu load","ts":"1466506544.000118"},{"type":"message","user":"U142E5N0P","text":"i've not noticed that, but the TPS is much higher","ts":"1466506570.000119"},{"type":"message","user":"U0XR6J961","text":"the input or the output?","ts":"1466506580.000120"},{"type":"message","user":"U0XR6J961","text":"how are the nodes connected?","ts":"1466506596.000121"},{"type":"message","user":"U142E5N0P","text":"`invoke` requests","ts":"1466506613.000122"},{"type":"message","user":"U142E5N0P","text":"the P2P network was kept same: 4 nodes","ts":"1466506636.000123"},{"type":"message","user":"U0XR6J961","text":"yes, but how are they connected","ts":"1466506643.000124"},{"type":"message","user":"U142E5N0P","text":"1 leader, the left three directly connect to peer1","ts":"1466506659.000125"},{"type":"message","user":"U0XR6J961","text":"switch?","ts":"1466506698.000126"},{"type":"message","user":"U142E5N0P","text":"the are on the same rack","ts":"1466506719.000127"},{"type":"message","user":"U0XR6J961","text":"okay","ts":"1466506723.000128"},{"type":"message","user":"U0XR6J961","text":"so how do you count TPS?","ts":"1466506732.000129"},{"type":"message","user":"U142E5N0P","text":"jmeter reports","ts":"1466506751.000130"},{"type":"message","user":"U0XR6J961","text":"so you don't know whether these invokes are committed to the chain?","ts":"1466506786.000131"},{"type":"message","user":"U142E5N0P","text":"i use a seperate `query` request to get the current chaincode state","ts":"1466506812.000132"},{"type":"message","user":"U0XR6J961","text":"and all invokes are committed?","ts":"1466506832.000133"},{"type":"message","user":"U142E5N0P","text":"yes","ts":"1466506837.000134"},{"type":"message","user":"U142E5N0P","text":"when jmeter stops, the state of chaincode become stable immediately.  but will wait tens of minutes when pbft is used","ts":"1466506862.000135"},{"type":"message","user":"U0XR6J961","text":"did you have a look at the profile?","ts":"1466506878.000136"},{"type":"message","user":"U142E5N0P","text":"not yet","ts":"1466506893.000137"},{"type":"message","user":"U0XR6J961","text":"okay","ts":"1466506896.000138"},{"type":"message","user":"U0XR6J961","text":"do you run with security enabled?","ts":"1466506903.000139"},{"type":"message","user":"U142E5N0P","text":"no","ts":"1466506909.000140"},{"type":"message","user":"U0XR6J961","text":"hmmm","ts":"1466506918.000141"},{"type":"message","user":"U0XR6J961","text":"yea, profile would be great","ts":"1466506937.000142"},{"type":"message","user":"U0XR6J961","text":"there should be a profile port you can connect to","ts":"1466506955.000143"},{"type":"message","user":"U142E5N0P","text":"profile for `pbft` was reported by <@U1CK6522F> above.  I've not made it for noops","ts":"1466506993.000144"},{"type":"message","user":"U0XR6J961","text":"that profile is incomplete","ts":"1466507015.000145"},{"type":"message","user":"U0XR6J961","text":"it doesn't show anything about pbft","ts":"1466507033.000146"},{"type":"message","user":"U0XR6J961","text":"but try batchsize = 1000","ts":"1466507040.000147"},{"type":"message","user":"U142E5N0P","text":"latest master branch should work fine?","ts":"1466507165.000148"},{"type":"message","user":"U0XR6J961","text":"it would be useful to use latest master, yes","ts":"1466507253.000149"},{"type":"message","user":"U142E5N0P","text":"okay.","ts":"1466507405.000150"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>:   here are the results for latest code with `batchsize:1000` \n\nJmeter shows a report of :  222s with 77TPS on average.\n\nAfter Jmeter stopped, fabic stopped in around 120s, as a result, the practical TPS is (222*77)\/(222+120) = 53\n\nAnd there's phoenoma that when I use a seperate `query` request to get chaincode status, it kept unchanged, while after all requests have been committed, it returns the eventual committed result.\n\nProfile report would be delivered later.","ts":"1466510460.000151"},{"type":"message","user":"U0XR6J961","text":"hmmm","ts":"1466510510.000152"},{"type":"message","user":"U0XR6J961","text":"so it stays at the initial value?","ts":"1466510537.000153"},{"type":"message","user":"U142E5N0P","text":"no, the status is correct","ts":"1466510556.000154"},{"type":"message","user":"U142E5N0P","text":"for example, the status shows `a=1000` at all time, and `a=-20800` in the end: each transaction is just a simple `a -=10`.  But `a=1000` is shown during the whole consensus process","ts":"1466510673.000155"},{"type":"message","user":"U142E5N0P","text":"so it seems the performance had been improved from 15(with batch size of 2) to 50(with batch size of 1000)?","ts":"1466510725.000156"},{"type":"message","user":"U0XR6J961","text":"weird","ts":"1466510731.000157"},{"type":"message","user":"U0XR6J961","text":"why doesn't it show intermediate results?","ts":"1466510750.000158"},{"type":"message","user":"U142E5N0P","text":"hmm, i've no idea..","ts":"1466510803.000159"},{"type":"message","user":"U142E5N0P","text":"i build image based on commits till 6905fecdb3d869c9047cbdfae5a764671e8174e1","ts":"1466510842.000160"},{"type":"message","user":"U142E5N0P","text":"could the consensus be processed with a pipeline design?  without pipelined processing, the throughput would not reach a relative large amount","ts":"1466510946.000161"},{"type":"message","user":"U142E5N0P","text":"for example, raft\/paxos based storage, such as etcd, could reach 10k write operations per second. although the consensus process of raft will take shorter time, such a large performance metric would not be reached by a simple sequential processing.","ts":"1466511255.000162"},{"type":"message","user":"U0XR6J961","text":"i don't understand","ts":"1466513492.000163"},{"type":"message","user":"U0XR6J961","text":"chaincode execution are sequential","ts":"1466513510.000164"},{"type":"message","user":"U0XR6J961","text":"they depend on current state and change it","ts":"1466513532.000165"},{"type":"message","user":"U142E5N0P","text":"This is the result when PR1924 had been applied:\n\nThe performance seems to be improved a lot. Jmeter shows a throughput of 4000TPS (without PR1924, it's 77TPS as mentioned above).  The practical commited speed seems to achieve 500, the 1000 batched requests are finished processing in 2 seconds. \n\nAlso there exist some evident bugs, for example, when I restart jmeter for another testing after fabric have committed all queued messages, the commits will not take into effect any more.","ts":"1466570251.000166"},{"type":"message","user":"U1CK6522F","text":"great! the throughput is 10X with this patch","edited":{"user":"U1CK6522F","ts":"1466579153.000000"},"ts":"1466579005.000167"},{"type":"message","user":"U0XR6J961","text":"that patch only improved the speed that much?","ts":"1466583542.000169"},{"type":"message","user":"U0XR6J961","text":"or did something in master change as well","ts":"1466583557.000170"},{"type":"message","user":"U0XR6J961","text":"yingfeng: what do you mean by commits will not take effect?","ts":"1466583581.000171"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>: the chaincode is a transaction of `a -= 10`,  after the first stress test, the state of chaincode status is `a = -198000`, which means around 20K transactions have been committed, while when jmeter is restarted to perform another stress test, the value of variable `a` keep unchanged","ts":"1466585042.000172"},{"type":"message","user":"U0XR6J961","text":"that is weird","ts":"1466586191.000173"},{"type":"message","user":"U0XR6J961","text":"can you provide debug logs?","ts":"1466586242.000174"},{"type":"message","user":"U142E5N0P","text":"sure,  it's here :  <https:\/\/transfer.sh\/CQMa0\/peer.tar.gz> \nlog level is set to `INFO`","ts":"1466587842.000175"},{"type":"message","user":"U0XR6J961","text":"info doesn't help","ts":"1466588645.000176"},{"type":"message","user":"U0Y14MWA2","text":"<@U0XR6J961> is batching now working or that PR is not yet merged?","ts":"1466588700.000177"},{"type":"message","user":"U0XR6J961","text":"batching works","ts":"1466588711.000178"},{"type":"message","user":"U0Y14MWA2","text":"ok","ts":"1466588714.000179"},{"type":"message","user":"U142E5N0P","text":"`debug` is too huge to upload","ts":"1466588732.000180"},{"type":"message","user":"U0XR6J961","text":"1924 is the algorithmic complexity fix","ts":"1466588735.000181"},{"type":"message","user":"U0XR6J961","text":"yingfeng: it would be sufficient to see the debug logs starting after the first batch is done","ts":"1466588772.000182"},{"type":"message","user":"U0XR6J961","text":"and then just run 10 requests or so","ts":"1466588782.000183"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>:    it's here:   <https:\/\/transfer.sh\/FJhMu\/peer.dbg.tar.gz>","ts":"1466589329.000184"},{"type":"message","user":"U0XR6J961","text":"yingfeng: somehow only vp1 and vp2 communicate?","ts":"1466590240.000185"},{"type":"message","user":"U0XR6J961","text":"could you supply the other peer logs as well?","ts":"1466590288.000186"},{"type":"message","user":"U142E5N0P","text":"<@U0XR6J961>: \npeer1: <https:\/\/transfer.sh\/yW65f\/peer1.dbg.tar.gz>\npeer2: <https:\/\/transfer.sh\/zeHvR\/peer2.dbg.tar.gz>\npeer3: <https:\/\/transfer.sh\/Dxf3f\/peer3.dbg.tar.gz>\npeer4: <https:\/\/transfer.sh\/apiaA\/peer4.dbg.tar.gz>\n\npeer1 is the root node,  peer3 is the one receiving stress requests","ts":"1466594274.000187"},{"type":"message","user":"U0XR6J961","text":"thanks","ts":"1466595462.000188"},{"type":"message","user":"U0XR6J961","text":"the system is totally overloaded","ts":"1466602297.000189"},{"type":"message","user":"U142E5N0P","text":"yeah, it's overloaded, but it could not recover.","ts":"1466603614.000190"},{"type":"message","user":"U0XR6J961","text":"i can't see anything","ts":"1466603652.000191"},{"type":"message","user":"U0XR6J961","text":"so with a single node pbft network running locally on my laptop, and the request generation also running locally, i get around 290 requests\/s closed loop performance","ts":"1466698273.000192"},{"type":"message","user":"U0XR6J961","text":"at batchsize=100","ts":"1466698287.000193"},{"type":"message","user":"U0XR6J961","text":"actually 297","ts":"1466698413.000194"},{"type":"message","user":"U0XR6J961","text":"with batchsize=10 i get around 263","ts":"1466698421.000195"},{"type":"message","user":"U0XR6J961","text":"117 with batchsize=1","ts":"1466698581.000196"},{"type":"message","user":"U0XR6J961","text":"somehow now performance is at 450\/s","ts":"1466775511.000197"},{"type":"message","user":"U0XR6J961","text":"with batch=50","ts":"1466775515.000198"},{"type":"message","user":"U0XR6J961","text":"ah, maybe because i reduced logging","ts":"1466775524.000199"},{"type":"message","user":"U0XR6J961","text":"468","ts":"1466775540.000200"},{"type":"message","user":"U0XPR4NP4","text":"<@U0XR6J961>: Yes, I noticed the same thing, reducing the logging significantly sped up the busywork tests (and exposed a few bad path bugs)","ts":"1466776308.000201"},{"type":"message","user":"U0XR6J961","text":"telemetry is very useful","ts":"1466776360.000202"},{"type":"message","user":"U0XR6J961","text":"good to see all these outstanding requests","ts":"1466776375.000203"},{"type":"message","user":"U0KPFAZNF","text":"<@U0XR6J961>: out of curiosity, what are you using for txn confirmation?","ts":"1466777461.000204"},{"type":"message","user":"U0KPFAZNF","text":"I need the same as we previously discussed, but I thought that event wasnt ready yet","ts":"1466777487.000205"},{"type":"message","user":"U0KPFAZNF","text":"so, id be curious to learn how you are doing it","ts":"1466777501.000206"},{"type":"message","user":"U0XR6J961","text":"have a look at my branch","ts":"1466777540.000207"},{"type":"message","user":"U0KPFAZNF","text":"(or is this something internal to the consensus layer?","ts":"1466777541.000208"},{"type":"message","user":"U0XR6J961","text":"no it is not","ts":"1466777633.000209"},{"type":"message","user":"U0XR6J961","text":"i have a fierce hack in the leger and rest layer","ts":"1466777649.000210"},{"type":"message","user":"U0XR6J961","text":"ghaskins: <https:\/\/github.com\/corecode\/fabric\/commits\/telemetry>","attachments":[{"service_name":"GitHub","title":"corecode\/fabric","title_link":"https:\/\/github.com\/corecode\/fabric\/commits\/telemetry","text":"Blockchain fabric code","fallback":"GitHub: corecode\/fabric","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/177979?v=3&s=400","from_url":"https:\/\/github.com\/corecode\/fabric\/commits\/telemetry","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1466777671.000211"},{"type":"message","user":"U0KPFAZNF","text":"ty","ts":"1466778623.000213"},{"type":"message","user":"U0XR6J961","text":"maybe we can rework it to be less hacky and put it in","ts":"1466779006.000214"},{"type":"message","user":"U0XR6J961","text":"so that we can start doing closed loop tests without adding patches","ts":"1466779019.000215","reactions":[{"name":"+1","users":["U0KPFAZNF"],"count":1}]},{"type":"message","user":"U0XPR4NP4","text":"<@U0XR6J961>: I know we discussed on the phone, would be nice to make this configurable if it can be done cleanly","ts":"1466779499.000216"},{"type":"message","user":"U0XR6J961","text":"what do you mean?","ts":"1466779566.000217"},{"type":"message","user":"U0XR6J961","text":"the rest submission?","ts":"1466779575.000218"},{"type":"message","user":"U0XR6J961","text":"or into pbft","ts":"1466779585.000219"},{"type":"message","user":"U0XPR4NP4","text":"I mean to flip the system from open loop to closed loop","ts":"1466779906.000220"},{"type":"message","user":"U0XR6J961","text":"i'm just talking about REST invokes that will optionally block until the transaction is committed","ts":"1466779954.000221"},{"type":"message","user":"U0XPR4NP4","text":"Ah okay","ts":"1466780546.000222"},{"type":"message","user":"U0KPFAZNF","text":"<@U0XR6J961>: even if we have a branch to work from, that might be a good stop-gap","ts":"1466786269.000223"},{"type":"message","user":"U0KPFAZNF","text":"what I have now is really weak","ts":"1466786283.000224"},{"type":"message","user":"U0UGH3X7X","text":"FYI for folks on this channel  <https:\/\/github.com\/hyperledger\/fabric\/pull\/2003>","attachments":[{"service_name":"GitHub","title":"increase consensus batchsize to 1000 by dongmingh \u00b7 Pull Request #2003 \u00b7 hyperledger\/fabric \u00b7 GitHub","title_link":"https:\/\/github.com\/hyperledger\/fabric\/pull\/2003","text":"Description To increase consensus batchsize to 1000 in config.yaml Motivation and Context This is to increase the performance with pbft consensus How Has This Been Tested? Compare the performa...","fallback":"GitHub: increase consensus batchsize to 1000 by dongmingh \u00b7 Pull Request #2003 \u00b7 hyperledger\/fabric","thumb_url":"https:\/\/avatars2.githubusercontent.com\/u\/17034559?v=3&s=400","from_url":"https:\/\/github.com\/hyperledger\/fabric\/pull\/2003","thumb_width":420,"thumb_height":420,"service_icon":"https:\/\/a.slack-edge.com\/e8ef6\/img\/unfurl_icons\/github.png","id":1}],"ts":"1466795022.000225"},{"type":"message","user":"U10Q62R8X","text":"In case someone is running things on Linux-on-z... here is a working preview of ECC P256 on z:\n\n<https:\/\/github.com\/linux-on-ibm-z\/go\/tree\/release-branch.go1.6-p256>\n\nand a possible way to experiment with it on hyperledger\n\n<https:\/\/github.com\/hyperledger\/fabric\/compare\/master...vpaprots:custom-golang>","attachments":[{"service_name":"GitHub","title":"linux-on-ibm-z\/go","title_link":"https:\/\/github.com\/linux-on-ibm-z\/go\/tree\/release-branch.go1.6-p256","text":"go - A port of the Go programming language to the IBM LinuxONE. Issues are monitored, and comments\/questions are welcome on our DeveloperWorks community.","fallback":"GitHub: linux-on-ibm-z\/go","thumb_url":"https:\/\/avatars0.githubusercontent.com\/u\/11740175?v=3&s=400","from_url":"https:\/\/github.com\/linux-on-ibm-z\/go\/tree\/release-branch.go1.6-p256","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1},{"service_name":"GitHub","title":"hyperledger\/fabric","title_link":"https:\/\/github.com\/hyperledger\/fabric\/compare\/master...vpaprots:custom-golang","text":"fabric - Fabric is a blockchain project in Incubation proposed to the community and documented at <https:\/\/goo.gl\/RYQZ5N>. Information on what Incubation entails can be found in the Hyperledger Proj...","fallback":"GitHub: hyperledger\/fabric","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/7657900?v=3&s=400","from_url":"https:\/\/github.com\/hyperledger\/fabric\/compare\/master...vpaprots:custom-golang","thumb_width":142,"thumb_height":142,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":2}],"ts":"1466821088.000227"},{"user":"U1JJ64P53","type":"message","subtype":"channel_join","text":"<@U1JJ64P53|eugenn> has joined the channel","ts":"1466852372.000229"},{"user":"U1JB7QCBD","type":"message","subtype":"channel_join","text":"<@U1JB7QCBD|ashnur> has joined the channel","ts":"1467124125.000230"},{"type":"message","user":"U0XR6J961","text":"somehow now i get 600 invoke\/sec","ts":"1467126510.000231"},{"type":"message","user":"U0ZJZBJLF","text":"I'm seeing the weirdest thing ever. with N=1 and F=0 (1 validator pbft batch) I get really lousy performance. Any ideas why?","edited":{"user":"U0ZJZBJLF","ts":"1467143407.000000"},"ts":"1467143287.000232"},{"type":"message","user":"U0XR6J961","text":"works for me","ts":"1467191015.000234"},{"type":"message","user":"U0XR6J961","text":"if i don't use a chaincode, but emulate the chaincode execution in the chaincode exec handler, i get between 2000 and 4000 invokes\/sec","ts":"1467200501.000235"},{"type":"message","user":"U0XR6J961","text":"instead of 600","ts":"1467200504.000236"},{"type":"message","user":"U0ZJZBJLF","text":"So I think we may have found our killer","ts":"1467200996.000237"},{"type":"message","user":"U0XR6J961","text":"pretty stable 4070 now","ts":"1467200999.000238"},{"type":"message","user":"U0XR6J961","text":"well, i said so since febuary","ts":"1467201012.000239"},{"type":"message","user":"U0ZJZBJLF","text":"I wasn't in the project at that time...","ts":"1467201054.000240"},{"type":"message","user":"U0ZJZBJLF","text":"BTW- does the chaincode execute in parallel the transactions? or 1-by-1?","ts":"1467201070.000241"},{"type":"message","user":"U0XR6J961","text":"sequentially","ts":"1467201076.000242"},{"type":"message","user":"U0ZJZBJLF","text":"so why is the gRPC channel to the peer synchronized then? in the chaincode?","ts":"1467201108.000243"},{"type":"message","user":"U0XR6J961","text":"what do you mean, synchronized","ts":"1467201261.000244"},{"type":"message","user":"U0ZJZBJLF","text":"there is a defer and a lock around it","ts":"1467201271.000245"},{"type":"message","user":"U0ZJZBJLF","text":"```\nhandler.serialLock.Lock()\n\tdefer handler.serialLock.Unlock()\nif err := handler.ChatStream.Send(msg); err != nil {\n```","edited":{"user":"U0ZJZBJLF","ts":"1467201363.000000"},"ts":"1467201341.000246"},{"type":"message","user":"U0ULK2JPP","text":"<@U0ZJZBJLF>: queries can be parallel and invokes are sequential","ts":"1467201651.000248"},{"type":"message","user":"U0ULK2JPP","text":"ie, multiple queries can be going on at the same time as 1 invoke","ts":"1467201692.000249"},{"type":"message","user":"U0ZJZBJLF","text":"That makes sense. But why is the channel synchronized then? doesn't it hinder performance?","ts":"1467201801.000250"},{"type":"message","user":"U0XR6J961","text":"still 4000 is a bit weak","ts":"1467201806.000251"},{"type":"message","user":"U0ZJZBJLF","text":"I mean- why not have multiple channels","ts":"1467201915.000252"},{"type":"message","user":"U0ULK2JPP","text":"The gRPC Sends is not thread safe and needs to be serialized","ts":"1467201927.000253"},{"type":"message","user":"U0ZJZBJLF","text":"yeah I understand that","ts":"1467201942.000254"},{"type":"message","user":"U0ULK2JPP","text":"ok...","ts":"1467201949.000255"},{"type":"message","user":"U0XR6J961","text":"they are not thread safe? wut","ts":"1467201961.000256"},{"type":"message","user":"U0ZJZBJLF","text":"but why not have multiple channels and select one \"free\" and send along it? HTTP\/2 allows multiple \"sessions\" in the same tcp connection","ts":"1467202004.000257"},{"type":"message","user":"U0ULK2JPP","text":"i cannot interleave two Send calls","ts":"1467202047.000258"},{"type":"message","user":"U0XR6J961","text":"yacovm: most grpcs interfaces are stream interfaces","ts":"1467202069.000259"},{"type":"message","user":"U0XR6J961","text":"for no reason","ts":"1467202072.000260"},{"type":"message","user":"U0ZJZBJLF","text":"two send calls, on 2 different gRPC channels","ts":"1467202082.000261"},{"type":"message","user":"U0XR6J961","text":"i mean in fabric","ts":"1467202086.000262"},{"type":"message","user":"U0ULK2JPP","text":"<@U0XR6J961> you mean use RPC insterad of \u201cChat\u201d Stream for each request (basically go request-response ?)","ts":"1467202212.000263"},{"type":"message","user":"U0XR6J961","text":"i don't know whether the chaincode interface should be that way","ts":"1467202240.000264"},{"type":"message","user":"U0ULK2JPP","text":"ok.","ts":"1467202410.000265"},{"type":"message","user":"U0ULK2JPP","text":"<@U0ZJZBJLF>: One thing\u2026 every chaincode gets its own handler\/channel. was not sure if you were thinking there was one handler for all chaincodes (so just wanted to clarify that)","edited":{"user":"U0ULK2JPP","ts":"1467202490.000000"},"ts":"1467202482.000266"},{"type":"message","user":"U0ZJZBJLF","text":"of course, it's in its own process, isn't it?","ts":"1467202671.000268"},{"type":"message","user":"U0ZJZBJLF","text":"I'm asking- if a CC instance can query in parallel (for example)- why can't it have K channels and submit the data on 1 of them? Because otherwise, we have (for example) N read-type transactions, 1 write type transaction, and they all \"queued\" on that same gRPC channel on which they send the messages through.","ts":"1467202754.000269"},{"type":"message","user":"U0ZJZBJLF","text":"If we have K channels we can send on them in parallel and maybe increase performance?","ts":"1467202791.000270"},{"type":"message","user":"U0XR6J961","text":"we're looking only at invoke performance","ts":"1467203449.000271"},{"type":"message","user":"U0ZJZBJLF","text":"because fabric is write-oriented?","edited":{"user":"U0ZJZBJLF","ts":"1467203494.000000"},"ts":"1467203474.000272"},{"type":"message","user":"U0XR6J961","text":"no, because that's the slow path","ts":"1467203604.000274"},{"type":"message","user":"U0XR6J961","text":"read is trivially scaled","ts":"1467203611.000275"},{"type":"message","user":"U0XR6J961","text":"just use more machines","ts":"1467203617.000276"},{"type":"message","user":"U0KM61BCP","text":"well, you certainly could horizontally scale query","ts":"1467204060.000277"},{"type":"message","user":"U0ULK2JPP","text":"right, in the end, the invoke serialization is the real problem","ts":"1467205608.000278"},{"type":"message","user":"U0ULK2JPP","text":"Just doing queries is not a problem at at all","ts":"1467205663.000279"},{"type":"message","user":"U0Y14MWA2","text":"<@U0XR6J961> how is batching impacting 4k tps throughput that you see?","ts":"1467206626.000280"},{"type":"message","user":"U0Y14MWA2","text":"btw is this 4k tps on your laptop?","ts":"1467206655.000281"},{"type":"message","user":"U0XR6J961","text":"yes, N=1, F=0, batchsize=100 on my dinky laptop","ts":"1467207192.000282"},{"type":"message","user":"U0Y14MWA2","text":"does changing batchsize \/ N changes things?","ts":"1467207911.000283"},{"type":"message","user":"U0Y14MWA2","text":"<@U0ZJZBJLF> perhaps you can shortcircuit execution like <@U0XR6J961> and repeat your tests?","edited":{"user":"U0Y14MWA2","ts":"1467208088.000000"},"ts":"1467207927.000284"},{"type":"message","user":"U0Y14MWA2","text":"4k tps on a laptop is becoming more decent...","ts":"1467208032.000285"},{"type":"message","user":"U0XR6J961","text":"vukolic: well, it's without chaincode :slightly_smiling_face:","ts":"1467208042.000286"},{"type":"message","user":"U0Y14MWA2","text":"we're still not there :slightly_smiling_face:","ts":"1467208046.000287"},{"type":"message","user":"U0Y14MWA2","text":"yes :slightly_smiling_face:","ts":"1467208051.000288"},{"type":"message","user":"U0ZJZBJLF","text":"<@U0Y14MWA2>:  if you can provide me a fork\/branch with a blocking-until-transaction-completed Invoke method in the REST part + the needed short-circuit code for the CC part I can...","ts":"1467211056.000290"},{"user":"U0MSG4RL7","type":"message","subtype":"channel_join","text":"<@U0MSG4RL7|dmurik> has joined the channel","ts":"1467216189.000291"},{"user":"U1HFNJB50","type":"message","subtype":"channel_join","text":"<@U1HFNJB50|c0rwin> has joined the channel","ts":"1467239491.000292"},{"type":"message","user":"U0XR6J961","text":"running two nodes locally with short-circuited chaincode, i get about 3000 transactions","ts":"1467293120.000293"},{"type":"message","user":"U0XR6J961","text":"but that may be my laptop being overloaded","ts":"1467293131.000294"},{"type":"message","user":"U0ZJZBJLF","text":"<@U0XR6J961>: , you mean you short-circuit this section?\n<https:\/\/github.com\/hyperledger\/fabric\/blob\/1ec46065c5f803ebd7f2b1da96c2a3ebcef7a455\/core\/chaincode\/chaincode_support.go#L616>","attachments":[{"service_name":"GitHub","title":"hyperledger\/fabric","title_link":"https:\/\/github.com\/hyperledger\/fabric\/blob\/1ec46065c5f803ebd7f2b1da96c2a3ebcef7a455\/core\/chaincode\/chaincode_support.go#L616","text":"fabric - Fabric is a blockchain project in Incubation proposed to the community and documented at <https:\/\/goo.gl\/RYQZ5N>. Information on what Incubation entails can be found in the Hyperledger Proj...","fallback":"GitHub: hyperledger\/fabric","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/7657900?v=3&s=400","from_url":"https:\/\/github.com\/hyperledger\/fabric\/blob\/1ec46065c5f803ebd7f2b1da96c2a3ebcef7a455\/core\/chaincode\/chaincode_support.go#L616","thumb_width":142,"thumb_height":142,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1467300561.000295"},{"type":"message","user":"U0XR6J961","text":"yea","ts":"1467300778.000297"},{"type":"message","user":"U0XR6J961","text":"actually in handler","ts":"1467300787.000298"},{"type":"message","user":"U0ZJZBJLF","text":"Theoretically speaking, if all peers submit the same order or transactions, isn't it possible to send a batch of them to the CC, and optimistically execute all of them, and only then have the peer read the batch of PutState generated by the CC (assuming the CC doesn't need to fetch via GetState)?","edited":{"user":"U0ZJZBJLF","ts":"1467300874.000000"},"ts":"1467300838.000299"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1467300914.000302"},{"type":"message","user":"U0XR6J961","text":"but that won't speed it up much","ts":"1467300927.000303"},{"type":"message","user":"U0ZJZBJLF","text":"why not?","ts":"1467300930.000304"},{"type":"message","user":"U0XR6J961","text":"because the chaincode still needs to ask for the state from the database","ts":"1467300942.000305"},{"type":"message","user":"U0ZJZBJLF","text":"but why can't we cache it?","ts":"1467300958.000306"},{"type":"message","user":"U0ZJZBJLF","text":"because other CCs use it?","ts":"1467300967.000307"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1467300970.000308"},{"type":"message","user":"U0ZJZBJLF","text":"But in the protocol spec it's written \"Each chaincode may define its own persistent state variables\"","ts":"1467301178.000309"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1467301215.000310"},{"type":"message","user":"U0XR6J961","text":"but one chaincode can invoke\/query another chaincode","ts":"1467301228.000311"},{"type":"message","user":"U0ZJZBJLF","text":"So what? why can't we keep the state in memory cached and only GetState when needed?","ts":"1467301334.000312"},{"type":"message","user":"U0ZJZBJLF","text":"as long as the same CC instance holds the state and no one changes these keys in the DB but itself, the calls via GetState either cached or not are coherent because it's the only writer to these keys","ts":"1467301397.000313"},{"type":"message","user":"U0XR6J961","text":"because then you need to make sure that the chaincode handles it right","ts":"1467301419.000314"},{"type":"message","user":"U0XR6J961","text":"you need to communicate rollbacks, aborts","ts":"1467301486.000315"},{"type":"message","user":"U0ZJZBJLF","text":"yeah I didn't say it's simple :slightly_smiling_face:","ts":"1467301495.000316"},{"type":"message","user":"U0XR6J961","text":"well, why","ts":"1467301499.000317"},{"type":"message","user":"U0ZJZBJLF","text":"to increase throughput, because right now it's like Stop&amp;Wait network scheduling","ts":"1467301517.000318"},{"type":"message","user":"U0XR6J961","text":"the new architecture design would put the burden on execution on the submitter","ts":"1467301574.000319"},{"type":"message","user":"U0XR6J961","text":"and on the endorsers, who can parallelize execution","ts":"1467301589.000320"},{"type":"message","user":"U0ZJZBJLF","text":"You're saying you can't employ this because it'd not work well in the new architecture?","ts":"1467301710.000321"},{"type":"message","user":"U0XR6J961","text":"i'm saying the new architecture will improve the performance","ts":"1467301804.000322"},{"type":"message","user":"U0ZJZBJLF","text":"ok","ts":"1467301899.000323"},{"type":"message","user":"U0XPR4NP4","text":"<@U0XR6J961> I'm having trouble replicating your setup. I've got 2 peers running, with f=0, batchsize=1000, off your simon\/chaincode-shortcircuit branch.  My CPU is basically idle, and I am getting only about 10 tps.  I'm wondering how you are ingressing your requests, presumably through the REST api?","ts":"1467307584.000324"},{"type":"message","user":"U0XR6J961","text":"jyellick: set outstanding to a larger number than batchsize","ts":"1467364208.000327"},{"type":"message","user":"U0XR6J961","text":"i suggest batchsize=200, outstanding=400","ts":"1467364228.000328"},{"type":"message","user":"U0XR6J961","text":"so looking at the profile, 30% of the time seems to be spent in the GC","ts":"1467368957.000329"},{"type":"message","user":"U0XR6J961","text":"and also quite some time in malloc (may be affected by gc)","ts":"1467368989.000330"},{"type":"message","user":"U0XR6J961","text":"and then a lot of protobufs functions","ts":"1467369001.000331"},{"type":"message","user":"U0XR6J961","text":"so if we want to reach 10k tps or so, we need to really engineer the systems to marshal as few times as possible, and we need to control our use of temporaries","ts":"1467369071.000332"},{"type":"message","user":"U0XPR4NP4","text":"<@U0XR6J961>: On my laptop, in vagrant with 8GB RAM, 4 cpus","ts":"1467380899.000333"},{"type":"message","user":"U0XPR4NP4","text":"f=0, n=2, batchsize=1000, outstanding=1500 yields tps=2200","ts":"1467380909.000334"},{"type":"message","user":"U0XPR4NP4","text":"f=1, n=4, batchsize=1000, outstanding=1500 yields tps=1400","ts":"1467380921.000335"},{"type":"message","user":"U0XR6J961","text":"how do you submit transactions?","ts":"1467380948.000336"},{"type":"message","user":"U0XR6J961","text":"i used batchsize=100, outstanding=200","ts":"1467380961.000337"},{"type":"message","user":"U0XPR4NP4","text":"I've been using SOAPUI","ts":"1467380973.000338"},{"type":"message","user":"U0XR6J961","text":"how come i get 3000 and you get 2200?","ts":"1467380977.000339"},{"type":"message","user":"U0XR6J961","text":"but i'm running bare","ts":"1467380988.000340"},{"type":"message","user":"U0XPR4NP4","text":"100 Threads, each submitting 1000 requests each to a single peer","ts":"1467380989.000341"},{"type":"message","user":"U0XR6J961","text":"no vagrant","ts":"1467380991.000342"},{"type":"message","user":"U0XPR4NP4","text":"Could certainly be related","ts":"1467380996.000343"},{"type":"message","user":"U0XR6J961","text":"oh i used 10 threads","ts":"1467381009.000344"},{"type":"message","user":"U0XPR4NP4","text":"I can try reducing the number of threads","ts":"1467381019.000345"},{"type":"message","user":"U0XR6J961","text":"yea","ts":"1467381023.000346"},{"type":"message","user":"U0XR6J961","text":"that should reduce the scheduling problems","ts":"1467381035.000347"},{"type":"message","user":"U0XR6J961","text":"is that with short circuit?","ts":"1467381043.000348"},{"type":"message","user":"U0XPR4NP4","text":"Yes","ts":"1467381046.000349"},{"type":"message","user":"U0XR6J961","text":"hum hum","ts":"1467381344.000350"},{"type":"message","user":"U0XPR4NP4","text":"Maybe it is just the inefficiency introduced inside of vagrant, though I thought you never run in vagrant, and things like the unit tests always ran appreciably faster in my laptop's vagrant","ts":"1467381866.000351"},{"type":"message","user":"U0XR6J961","text":"yea odd","ts":"1467382145.000352"},{"type":"message","user":"U0XPR4NP4","text":"How are you driving load? I'm seeing SOAPUI use up an unreasonable amount of CPU","ts":"1467384998.000353"},{"type":"message","user":"U0XR6J961","text":"i'm using my rest-bench","ts":"1467385438.000354"},{"type":"message","user":"U0XR6J961","text":"`.\/rest-bench -request '{\"method\": \"invoke\", \"jsonrpc\": \"2.0\", \"ID\": \"hi\", \"params\": {\"chaincodeID\":{\"name\":\"a5389f7dfb9efae379900a41db1503fea2199fe400272b61ac5fe7bd0c6b97cf10ce3aa8dd00cd7626ce02f18accc7e5f2059dae6eb0786838042958352b89fb\"}, \"type\":1, \"ctorMsg\":{\"function\": \"invoke\", \"args\": [\"a\", \"b\", \"1\"]}}}' -url http:\/\/0:5001\/chaincode -parallel 10`","edited":{"user":"U0XR6J961","ts":"1467385469.000000"},"ts":"1467385463.000355"},{"type":"message","user":"U0XPR4NP4","text":"Is that somewhere I can grab?","ts":"1467385514.000357"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1467386207.000358"},{"type":"message","user":"U0XR6J961","text":"<https:\/\/github.com\/corecode\/rest-bench>","attachments":[{"service_name":"GitHub","title":"corecode\/rest-bench","title_link":"https:\/\/github.com\/corecode\/rest-bench","text":"Contribute to rest-bench development by creating an account on GitHub.","fallback":"GitHub: corecode\/rest-bench","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/177979?v=3&s=400","from_url":"https:\/\/github.com\/corecode\/rest-bench","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1467386237.000359"},{"user":"U0YM41HA5","type":"message","subtype":"channel_join","text":"<@U0YM41HA5|mandler> has joined the channel","ts":"1467627678.000361"},{"type":"message","user":"U0XR6J961","text":"seems when we ignore chaincode execution, performance now is dominated by GC and sha3","ts":"1467636147.000362"},{"type":"message","user":"U0XR6J961","text":"and analyzing the heap profile, mostly by marshalling\/unmarshalling","ts":"1467636200.000363"},{"type":"message","user":"U1CK6522F","text":"As suggested by simon, and I am posting my investigation on chaincode execution performance here:\n(1) Modify TestExecuteInvokeTransaction in core\/chaincode\/exectransaction_test.go:534 *It takes 20s to execute 10000 transactions on chaincode_example02*\n```\n    start := time.Now()\n    for i := 0; i &lt; 10000; i++ {\n        , , _, err := invoke(ctxt, spec, pb.Transaction_CHAINCODE_INVOKE)\n        if err != nil {\n            return fmt.Errorf(\"Error invoking &lt;%s&gt;: %s\", chaincodeID, err)\n        }\n    }\n    elapse := time.Now().Sub(start).Nanoseconds()\n    fmt.Printf(\"total time: %d\\n\", elapse)\n```\n\n(2) Modify Invoke in examples\/chaincode\/go\/chaincode_example02\/chaincode_example02.go:74 *it takes 10s to execute 10000 empty transactions*\nfunc (t *SimpleChaincode) Invoke(stub *shim.ChaincodeStub, function string, args []string) ([]byte, error) {\n   return nil, nil\n}\n\n(3) Modify TestExecuteInvokeTransaction in core\/chaincode\/exectransaction_test.go:534 *It takes 0.14s to execute 10000 transactions on peer*\n``` \n\tstart := time.Now()\n\tfor i := 0; i &lt; N; i++ {\n\t\tledgerObj, _ := ledger.GetLedger()\n\t\tledgerObj.TxBegin(\"1\")\n\n\t\tchaincodeID := cID.Name\n\t\tastr, _ := ledgerObj.GetState(chaincodeID, \"a\", false)\n\t\tbstr, _ := ledgerObj.GetState(chaincodeID, \"b\", false)\n\t\taval, _ := strconv.Atoi(string(astr))\n\t\tbval, _ := strconv.Atoi(string(bstr))\n\t\taval -= 10\n\t\tbval += 10\n\t\tastr = []byte(strconv.Itoa(aval))\n\t\tbstr = []byte(strconv.Itoa(bval))\n\t\tledgerObj.SetState(chaincodeID, \"a\", astr)\n\t\tledgerObj.SetState(chaincodeID, \"b\", bstr)\n\t\tledgerObj.TxFinished(\"1\", true)\n\t\t\/\/_, _, _, err := invoke(ctxt, spec, pb.Transaction_CHAINCODE_INVOKE)\n\t\t\/\/if err != nil {\n\t\t\/\/\treturn fmt.Errorf(\"Error invoking &lt;%s&gt;: %s\", chaincodeID, err)\n\t\t\/\/}\n\t}\n\telapse := time.Now().Sub(start).Nanoseconds()\n```\n\n(4) Modify TestExecuteDeploySysChaincode in core\/system_chaincode\/systemchaincode_test.go:193 *It takes 3.55s to execute 10000 transactions on sample syscc*\n```\n\tstart := time.Now()\n\tfor i := 0; i &lt; 10000; i++ {\n\t\t_, _, _, err = invoke(ctxt, spec, pb.Transaction_CHAINCODE_INVOKE)\n\t}\n\telapse := time.Now().Sub(start).Nanoseconds()\n\tfmt.Printf(\"total time: %d\\n\", elapse)\n```","ts":"1467809184.000364"},{"type":"message","user":"U1JB7QCBD","text":"zuowang: what kind of machine was this running on?","ts":"1467810093.000365"},{"type":"message","user":"U0XR6J961","text":"it really doesn't matter much","ts":"1467810277.000366"},{"type":"message","user":"U1JB7QCBD","text":"dunno, for me it seems like a significant factor to judge these numbers","ts":"1467820231.000367"},{"type":"message","user":"U0XR6J961","text":"why?","ts":"1467826490.000368"},{"type":"message","user":"U0KM61BCP","text":"I\u2019m unclear why system chaincode is taking so much time\u2026 any thoughts?","ts":"1467828201.000369"},{"type":"message","user":"U0XR6J961","text":"<@U0ULK2JPP>: any ideas?","ts":"1467828849.000370"},{"type":"message","user":"U0XR6J961","text":"maybe there also internal grpc happening?","ts":"1467828867.000371"},{"type":"message","user":"U0ULK2JPP","text":"<@U0KM61BCP> <@U0XR6J961>  the system chaincode still retains the chaincode machinery on the peer side and the the chaincode side (the FSM for example) via common code. Only the transport is different (grpc\/TCP vs channels\/goroutines)","ts":"1467830858.000372"},{"type":"message","user":"U0XR6J961","text":"so why is it so slow then?","ts":"1467830933.000373"},{"type":"message","user":"U0ULK2JPP","text":"hmm because it still retains the chaincode machinery on both sides","ts":"1467831090.000374"},{"type":"message","user":"U0ULK2JPP","text":"?","ts":"1467831091.000375"},{"type":"message","user":"U0ULK2JPP","text":"there should be a factor improvement between docker chaincode and system chaincode though","ts":"1467831112.000376"},{"type":"message","user":"U0KM61BCP","text":"yeah but it isn\u2019t what I would have expected","ts":"1467831711.000377"},{"type":"message","user":"U0KM61BCP","text":"is it doing the marshaling\/unmarshaling?","ts":"1467831719.000378"},{"type":"message","user":"U0XR6J961","text":"well this would be an easy candidate for profiling","ts":"1467831978.000379"},{"type":"message","user":"U0ULK2JPP","text":"The grpc protobuf marshalling\/unmarshalling is not there. Unlike the direct Database calls, there\u2019s back and forth between chaincode and the peer for every ledger access. The mechanics of this back and forth to allow for constraints (serial invokes vs parallel etc) woud likely be a big part","ts":"1467832702.000380"},{"type":"message","user":"U0ULK2JPP","text":"we _could_ figure out direct access from chaincode to ledger to break some of the chitchat\u2026 but then we\u2019ll have to refactor common code","ts":"1467832765.000381"},{"type":"message","user":"U0ULK2JPP","text":"on a different note, the other thing I though we could do fairly easily with docker chaincodes is to execute transactions to different chaincodes concurrently. On a multichaincode system we immediately get more utilization","ts":"1467832957.000382"},{"type":"message","user":"U0XR6J961","text":"what if one chaincode calls the other?","ts":"1467833060.000383"},{"type":"message","user":"U0ULK2JPP","text":"back of the que","ts":"1467833090.000384"},{"type":"message","user":"U0ULK2JPP","text":"so each chaincode really has a q of transactions","ts":"1467833145.000385"},{"type":"message","user":"U0ULK2JPP","text":"I\u2019ve been meaning to try it out in a branch\u2026 hopefully soon","ts":"1467833418.000386"},{"type":"message","user":"U0XR6J961","text":"what do you mean, back of the queue?","ts":"1467833461.000387"},{"type":"message","user":"U0XR6J961","text":"then the semantics work completely differently","ts":"1467833467.000388"},{"type":"message","user":"U0XR6J961","text":"how do you get a proper total order?","ts":"1467833494.000389"},{"type":"message","user":"U0ULK2JPP","text":"each of the chaincode will have a q of transactions","ts":"1467833505.000390"},{"type":"message","user":"U0ULK2JPP","text":"this would only for _execution_","ts":"1467833513.000391"},{"type":"message","user":"U0ULK2JPP","text":"not for ordering","ts":"1467833518.000392"},{"type":"message","user":"U0ULK2JPP","text":"the execute call would have to synchronously wait for the executions and reurn the transactions when the batch is complete","ts":"1467833602.000393"},{"type":"message","user":"U0ULK2JPP","text":"again this only makes a difference when there are  txs to multiple chaincodes.","ts":"1467833652.000394"},{"type":"message","user":"U0XR6J961","text":"not impressed","ts":"1467833661.000395"},{"type":"message","user":"U0ULK2JPP","text":"because","ts":"1467833667.000396"},{"type":"message","user":"U0ULK2JPP","text":"if you have 10 transactions","ts":"1467833679.000397"},{"type":"message","user":"U0ULK2JPP","text":"you could be executing them in parallel","ts":"1467833688.000398"},{"type":"message","user":"U0XR6J961","text":"sure","ts":"1467833705.000399"},{"type":"message","user":"U0XR6J961","text":"but that's why we have v2","ts":"1467833719.000400"},{"type":"message","user":"U0ULK2JPP","text":"right","ts":"1467833724.000401"},{"type":"message","user":"U0XR6J961","text":"where we can look at the pre\/postimage","ts":"1467833728.000402"},{"type":"message","user":"U0XR6J961","text":"and we can see directly which executions are independent","ts":"1467833739.000403"},{"type":"message","user":"U0XR6J961","text":"and then can run all of them in parallel","ts":"1467833747.000404"},{"type":"message","user":"U0XR6J961","text":"possibly even on separate machines","ts":"1467833753.000405"},{"type":"message","user":"U0XR6J961","text":"treat it like a database","ts":"1467833771.000406"},{"type":"message","user":"U0ULK2JPP","text":"maybe I\u2019m missing something\u2026.. in the endorser, when it receives 10 transactions how does it know how to execute them in parallel ?","ts":"1467833879.000407"},{"type":"message","user":"U0XR6J961","text":"it receives the pre and postimage","ts":"1467833891.000408"},{"type":"message","user":"U0ULK2JPP","text":"don\u2019t you have to execute first when submitted ?","ts":"1467833928.000409"},{"type":"message","user":"U0XR6J961","text":"if pre and postimages do not intersect, they are independent","ts":"1467833931.000410"},{"type":"message","user":"U0XR6J961","text":"the submitting peer sends pre and post image","ts":"1467833949.000411"},{"type":"message","user":"U0XR6J961","text":"or at least the keys","ts":"1467833965.000412"},{"type":"message","user":"U0XR6J961","text":"that's the whole reason why we want to redesign it","ts":"1467834011.000413"},{"type":"message","user":"U0XR6J961","text":"so that execution can be scaled","ts":"1467834019.000414"},{"type":"message","user":"U0ULK2JPP","text":"so client-&gt;submitting peer (execute chaincode) -&gt; endorsers \u2026\u2026\u2026\u2026\u2026. consensus ?","ts":"1467834058.000415"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1467834066.000416"},{"type":"message","user":"U0XR6J961","text":"endorsers also execute","ts":"1467834074.000417"},{"type":"message","user":"U0ULK2JPP","text":"right","ts":"1467834077.000418"},{"type":"message","user":"U0ULK2JPP","text":"that\u2019s what I thought","ts":"1467834081.000419"},{"type":"message","user":"U0ULK2JPP","text":"and thats where I thought you are going to have the same issue","ts":"1467834092.000420"},{"type":"message","user":"U0ULK2JPP","text":"but perhaps endorsers don\u2019t \u201cexecute\" using chaincode ?","ts":"1467834126.000421"},{"type":"message","user":"U0XR6J961","text":"of course they do","ts":"1467834133.000422"},{"type":"message","user":"U0XR6J961","text":"they have to","ts":"1467834135.000423"},{"type":"message","user":"U0ULK2JPP","text":"then I don\u2019t understand how the  parallelization can NOT help there as well","ts":"1467834272.000424"},{"type":"message","user":"U0XR6J961","text":"yes it does","ts":"1467834299.000425"},{"type":"message","user":"U0XR6J961","text":"but you can look at which jobs to parallelize","ts":"1467834315.000426"},{"type":"message","user":"U0XR6J961","text":"actually, all can be parallelized, because the state doesn't get changed by execution","ts":"1467834346.000427"},{"type":"message","user":"U0ULK2JPP","text":"ok\u2026. I still see need to do the kind of parallization. I only claim we can do it even now based on just the chaincodes being executed","ts":"1467834457.000428"},{"type":"message","user":"U0XR6J961","text":"but how do you deal with the fact that some chaincodes can call other chaincodes?","ts":"1467834540.000429"},{"type":"message","user":"U0XR6J961","text":"i think we need to look more into the execution overhead","ts":"1467834583.000430"},{"type":"message","user":"U0XR6J961","text":"why is it 20x","ts":"1467834588.000431"},{"type":"message","user":"U0XR6J961","text":"and only 6x between system cc and real cc","ts":"1467834776.000436"},{"type":"message","user":"U0ULK2JPP","text":"c-c won\u2019t be direct call like it is today but will have to be added to the que of tx for that chaincode","ts":"1467835061.000437"},{"type":"message","user":"U0ULK2JPP","text":"direct DB GetState \/ PutState instead of peer-chaincode exchange has overheads","ts":"1467835132.000438"},{"type":"message","user":"U0ULK2JPP","text":"some of it is minimized by system chaincode by avoiding grpc channel calls","ts":"1467835165.000439"},{"type":"message","user":"U0XR6J961","text":"well it seems that the difference ix 6x between syscc and real cc","ts":"1467876960.000440"},{"type":"message","user":"U0XR6J961","text":"compared to another 20x between syscc and direct emulated cc","ts":"1467876986.000441"},{"type":"message","user":"U0XR6J961","text":"that tells me that the chaincode coordination is inefficient, and not grpc","ts":"1467877006.000442"},{"type":"message","user":"U0ULK2JPP","text":"I\u2019m not saying there may not be room for improvement. There probably is.","ts":"1467892176.000443"},{"type":"message","user":"U0ULK2JPP","text":"What I _am_ saying this this","ts":"1467892190.000444"},{"type":"message","user":"U0ULK2JPP","text":"a simple transaction to do invoke just doing  a GetState call from Chaincode has to translate to (1) send peer-chaincode message to call the invoke (2) chaincode-peer GetState message (3) peer-ledger GetState call and (4) peer-chaincode with GetState response (5) chaincode-peer \u201ccomplete\u201d transaction message","ts":"1467892387.000445"},{"type":"message","user":"U0ULK2JPP","text":"the simulation comparison does just the (3)","ts":"1467892401.000446"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1467892499.000447"},{"type":"message","user":"U0XR6J961","text":"but goroutines and blocking channels have a few ns of context switch time","ts":"1467892522.000448"},{"type":"message","user":"U0XR6J961","text":"so that can't be it","ts":"1467892530.000449"},{"type":"message","user":"U0ULK2JPP","text":"maybe but total rarely not sum of the parts.","ts":"1467892616.000450"},{"type":"message","user":"U0ULK2JPP","text":"I haven\u2019t closely studied the dynamics yet","ts":"1467892680.000451"},{"type":"message","user":"U0ULK2JPP","text":"getting ready for work\u2026 continue conv. later in a bit","ts":"1467892718.000452"},{"type":"message","user":"U12452RAP","text":"can anyone help me for this issue?\n<https:\/\/github.com\/hyperledger\/fabric\/issues\/2129>","attachments":[{"service_name":"GitHub","title":"Performance test Java chaincode \u00b7 Issue #2129 \u00b7 hyperledger\/fabric \u00b7 GitHub","title_link":"https:\/\/github.com\/hyperledger\/fabric\/issues\/2129","text":"Description Java chaincode has been added. It would be great to see some performance numbers to see what kind of difference (if any) there is between Java and Go chaincode. <https:\/\/github.com\/h>...","fallback":"GitHub: Performance test Java chaincode \u00b7 Issue #2129 \u00b7 hyperledger\/fabric","thumb_url":"https:\/\/avatars1.githubusercontent.com\/u\/4872087?v=3&s=400","from_url":"https:\/\/github.com\/hyperledger\/fabric\/issues\/2129","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/a.slack-edge.com\/e8ef6\/img\/unfurl_icons\/github.png","id":1}],"ts":"1468415053.000453"},{"type":"message","user":"U0ULK2JPP","text":"<@U12452RAP>: I can try \u2026 what do you need ?","ts":"1468415201.000455"},{"user":"U1RJ0M1EC","text":"<@U1RJ0M1EC|voodoo> has joined the channel","type":"message","subtype":"channel_join","ts":"1468544540.000456"},{"user":"U1S54EHL7","text":"<@U1S54EHL7|steven.lebowitz> has joined the channel","type":"message","subtype":"channel_join","ts":"1468594567.000457"},{"user":"U17HK4VQR","text":"<@U17HK4VQR|ikocsis> has joined the channel","type":"message","subtype":"channel_join","ts":"1468882387.000002"},{"type":"message","user":"U17HK4VQR","text":"Hi all, it's really nice to see that there's a dedicated channel for performance and benchmarking. After some rough initial measurements (and creating setup automation for AWS and implementing some telemetry), we are planning to do some \"serious\" performance testing on fabric. As there still seem not to be too much support for this in the code base - busywork is nice and we are looking at it, but does not seem to address all aspects - my question is this: what harness\/automation do you use for performance measurement and\/or benchmarking? Does anyone already have patches for telemetry that could be shared? (I seem not to be able top see the archive of the channel, so apologies if earlier posts would answer my question...)","edited":{"user":"U17HK4VQR","ts":"1468884757.000000"},"ts":"1468884681.000003"},{"type":"message","user":"U0XQ35CDD","text":"<@U17HK4VQR>: have a look at Simon's telemetry branch: <https:\/\/github.com\/corecode\/fabric\/tree\/telemetry>","attachments":[{"service_name":"GitHub","title":"corecode\/fabric","title_link":"https:\/\/github.com\/corecode\/fabric\/tree\/telemetry","text":"Blockchain fabric code","fallback":"GitHub: corecode\/fabric","thumb_url":"https:\/\/avatars3.githubusercontent.com\/u\/177979?v=3&s=400","from_url":"https:\/\/github.com\/corecode\/fabric\/tree\/telemetry","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1468886262.000005"},{"user":"U1GLPP8QN","text":"<@U1GLPP8QN|deeflorian> has joined the channel","type":"message","subtype":"channel_join","ts":"1468914626.000007"},{"type":"message","user":"U17HK4VQR","text":"Kostas - thanks, much appreciated, we are looking into it.","ts":"1468926018.000008"},{"type":"message","user":"U0XR6J961","text":"ikocsis: what kind of benchmark are you interested in?","ts":"1468927673.000009"},{"type":"message","user":"U0XR6J961","text":"overall performance depends mostly on the complexity of the chaincode","ts":"1468927695.000010"},{"type":"message","user":"U0ULK2JPP","text":"<@U0XR6J961> I started looking into some results that were measured by iterating over the \u201cinvoke\u201d method in the unit tests in chaincode and system_chaincode\u2026. each invoke calls \u201cCommitTxBatch\u201d which creates a block per invoke","ts":"1468929347.000011"},{"type":"message","user":"U0ULK2JPP","text":"should remove that when measuring chaincode times\u2026 ok to leave the state writes to ledger","ts":"1468929402.000012"},{"type":"message","user":"U0XR6J961","text":"muralisr: aha","ts":"1468929422.000013"},{"type":"message","user":"U0ULK2JPP","text":"will give you some perf back","ts":"1468929436.000014"},{"type":"message","user":"U0XR6J961","text":"do we have actual `go test` benchmarks?","ts":"1468929442.000015"},{"type":"message","user":"U0XR6J961","text":"that would be super useful","ts":"1468929448.000016"},{"type":"message","user":"U0ULK2JPP","text":"agreed","ts":"1468929452.000017"},{"type":"message","user":"U0ULK2JPP","text":"I have my own for now\u2026 need to convert into go test","ts":"1468929464.000018"},{"type":"message","user":"U0XR6J961","text":"it's very simple","ts":"1468929485.000019"},{"type":"message","user":"U0XR6J961","text":"`func BenchFoo(b *testing.B) { for i := 0; i &lt; b.N; i++ { ... } }`","edited":{"user":"U0XR6J961","ts":"1468929515.000000"},"ts":"1468929512.000020"},{"type":"message","user":"U0ULK2JPP","text":"I wrote one for events","ts":"1468929517.000022"},{"type":"message","user":"U0ULK2JPP","text":"right","ts":"1468929518.000023"},{"type":"message","user":"U0ULK2JPP","text":"will do it","ts":"1468929540.000024"},{"type":"message","user":"U17HK4VQR","text":"Hi <@U0XR6J961> - we are actually working towards fabric performance modelling; ideally, that would need a test driver with parameterizable workloads (and well defined metrics) + test setup automation for distributed deployments + \"telemetry\"\/introspection (e.g. peer-internal call latencies, peer to peer messaging latencies, etc.). A bit of this we already have internally but I would really like to have an overview of the existing options.","ts":"1468930176.000025"},{"type":"message","user":"U0XR6J961","text":"interesting","ts":"1468930228.000026"},{"type":"message","user":"U0XR6J961","text":"yea check out my telemetry branch","ts":"1468930247.000027"},{"type":"message","user":"U0XR6J961","text":"it gives some queue sizes at least","ts":"1468930256.000028"},{"type":"message","user":"U0XR6J961","text":"but it seems that people are not really interested in performance","ts":"1468930271.000029"},{"type":"message","user":"U0XR6J961","text":"or only occasionally, then they freak out about poor performance, then they forget about it again","ts":"1468930291.000030"},{"type":"message","user":"U17HK4VQR","text":"<@U0XR6J961>, w.r.t. chaincode execution dominating performance: does that come from experience, or is there data (that maybe we could look at)?","ts":"1468930324.000031"},{"type":"message","user":"U17HK4VQR","text":"Well, we are getting into a fabric performance research project here (Budapest University of Technology and Economics), so it does interest us more than cursorily :slightly_smiling_face: Kostas (Christidis) can give you more detail on that, if you are interested.","ts":"1468930479.000032"},{"type":"message","user":"U17HK4VQR","text":"And for what it's worth, I do know that the guys at Digital Asset Holdings here in Budapest are concerned about performance, have some simple (last time I checked) measurement tooling in their fork and run experiments on EC2. But I don't know much more.","ts":"1468930632.000033"},{"type":"message","user":"U0XR6J961","text":"both","ts":"1468930754.000034"},{"type":"message","user":"U0XR6J961","text":"the latency for RPC between chaincode and peer seems to be the limiting factor","ts":"1468930845.000035"},{"type":"message","user":"U17HK4VQR","text":"thanks, that's good to know\none last thing for now: does that remain so with pbft &amp; scaling up the number of peers? (although we haven't tried n&gt;4, I don't know whether it works at all)","ts":"1468931334.000036"},{"type":"message","user":"U0XR6J961","text":"well if you have n=1000, f=333, probably not","ts":"1468931427.000037"},{"type":"message","user":"U0XR6J961","text":"but you can compensate for this by batching more transactions","ts":"1468931443.000038"},{"type":"message","user":"U0XR6J961","text":"say you need 1s to do consensus with N=1000, if you batch more requests than you can execute in 1s, you still are limited by the execution speed","ts":"1468931519.000039"},{"type":"message","user":"U0XR6J961","text":"now of course this isn't quite right, because our pbft, the primary broadcasts all requests, which means that the primary's network bandwidth is the limiting factor","ts":"1468931562.000040"},{"type":"message","user":"U0XR6J961","text":"but i guess you could somehow put the burden on the submitter, or use multicast (if you're in a data center)","ts":"1468931604.000041"},{"type":"message","user":"U17HK4VQR","text":"ok, I understand and this is really helpful, thanks","ts":"1468931694.000042"},{"user":"U1296EA0M","text":"<@U1296EA0M|maro> has joined the channel","type":"message","subtype":"channel_join","ts":"1469061559.000043"},{"user":"U1SDX7EQZ","text":"<@U1SDX7EQZ|liewsc> has joined the channel","type":"message","subtype":"channel_join","ts":"1469065050.000044"},{"user":"U1U7BR1KP","text":"<@U1U7BR1KP|ray> has joined the channel","type":"message","subtype":"channel_join","ts":"1469202536.000045"},{"type":"message","user":"U0NCW1DPX","text":"Hi, I am reading the op\/go-logging library recently, I find the go-logging does not support write the logs asynchronous (<https:\/\/github.com\/op\/go-logging\/blob\/master\/log_nix.go#L59>, <https:\/\/github.com\/op\/go-logging\/blob\/master\/logger.go#L166>) by my understanding. It will effect our performance definitely. We should move to use other better alternatives, anyone has some comments on this. <@U0XR6J961> what do u think?","attachments":[{"service_name":"GitHub","title":"op\/go-logging","title_link":"https:\/\/github.com\/op\/go-logging\/blob\/master\/log_nix.go#L59","text":"go-logging - Golang logging library","fallback":"GitHub: op\/go-logging","thumb_url":"https:\/\/avatars1.githubusercontent.com\/u\/55245?v=3&s=400","from_url":"https:\/\/github.com\/op\/go-logging\/blob\/master\/log_nix.go#L59","thumb_width":400,"thumb_height":400,"service_icon":"https:\/\/github.com\/apple-touch-icon.png","id":1}],"ts":"1469365023.000046"},{"type":"message","user":"U0XR6J961","text":"gengjh: if we want to log a lot, probably","ts":"1469441573.000048"},{"type":"message","user":"U0NCW1DPX","text":"ok, I will open an issue to trace this.","ts":"1469450596.000049"},{"type":"message","user":"U0XR6J961","text":"gengjh: i guess you could use a memory backend which lazily flushes the log?","ts":"1469450696.000050"},{"type":"message","user":"U0NCW1DPX","text":"yes, it is another choice, but it is not default one. do we support to config this in our core.yaml?","ts":"1469450809.000051"},{"type":"message","user":"U0XR6J961","text":"no","ts":"1469451156.000052"},{"type":"message","user":"U0XR6J961","text":"logging and config are two areas that need work","ts":"1469451167.000053"},{"type":"message","user":"U0XR6J961","text":"gengjh: logging right now is not a performance bottleneck if you run it at info level","ts":"1469451244.000054"},{"type":"message","user":"U0XR6J961","text":"gengjh: are you struggling with performance?","ts":"1469451269.000055"},{"type":"message","user":"U0NCW1DPX","text":"yes, I am. we have requirement to handle 24000 transaction \/s","ts":"1469451381.000056"},{"type":"message","user":"U0XR6J961","text":"okay","ts":"1469451401.000057"},{"type":"message","user":"U0XR6J961","text":"do you need to dynamically deploy chaincode?","ts":"1469451409.000058"},{"type":"message","user":"U0NCW1DPX","text":"no we need not","ts":"1469451424.000059"},{"type":"message","user":"U0XR6J961","text":"okay","ts":"1469451427.000060"},{"type":"message","user":"U0XR6J961","text":"then i suggest getting rid of dockerized chaincode","ts":"1469451440.000061"},{"type":"message","user":"U0XR6J961","text":"and compile it in as system chaincode","edited":{"user":"U0XR6J961","ts":"1469451455.000000"},"ts":"1469451451.000062"},{"type":"message","user":"U0NCW1DPX","text":"you mean run the chaincode with peer process?","ts":"1469451481.000064"},{"type":"message","user":"U0XR6J961","text":"yes","ts":"1469451486.000065"},{"type":"message","user":"U0NCW1DPX","text":"why?","ts":"1469451494.000066"},{"type":"message","user":"U0XR6J961","text":"because it is faster","ts":"1469451500.000067"},{"type":"message","user":"U0NCW1DPX","text":"so the bottleneck is in the docker container or grpc call?","ts":"1469451557.000068"},{"type":"message","user":"U0XR6J961","text":"one bottleneck","ts":"1469451567.000069"},{"type":"message","user":"U0XR6J961","text":"so you need 24ktps, at how many peers?","ts":"1469451585.000070"},{"type":"message","user":"U0XR6J961","text":"all invokes or queries?","ts":"1469451604.000071"},{"type":"message","user":"U0NCW1DPX","text":"in alpha release we will setup around 20 peers (include 10 vps), 24ktps all invokes.","edited":{"user":"U0NCW1DPX","ts":"1469451714.000000"},"ts":"1469451690.000072"},{"type":"message","user":"U0XR6J961","text":"how large are your invokes?","ts":"1469451715.000074"},{"type":"message","user":"U0XR6J961","text":"and do you use security or not?","ts":"1469451725.000075"},{"type":"message","user":"U0NCW1DPX","text":"1kb","ts":"1469451727.000076"},{"type":"message","user":"U0NCW1DPX","text":"security","ts":"1469451733.000077"},{"type":"message","user":"U0XR6J961","text":"yea no","ts":"1469451743.000078"},{"type":"message","user":"U0XR6J961","text":"not going to happen","ts":"1469451746.000079"},{"type":"message","user":"U0XR6J961","text":"just think about it:","ts":"1469451753.000080"},{"type":"message","user":"U0XR6J961","text":"24ktps*1kB\/sec = 24MB\/sec","ts":"1469451768.000081"},{"type":"message","user":"U0XR6J961","text":"so just to get the transactions to ONE peer, you need 24MB\/sec","ts":"1469451783.000082"},{"type":"message","user":"U0XR6J961","text":"in the way pbft is written at the moment, the primary sends out all these messages (after receiving them), so it needs to send 240MB\/sec","ts":"1469451836.000083"},{"type":"message","user":"U0NCW1DPX","text":"so maybe I need consider to compress the data?","ts":"1469451865.000084"},{"type":"message","user":"U0XR6J961","text":"do you think it is realistic that you can significantly compress the data?","ts":"1469451899.000085"},{"type":"message","user":"U0XR6J961","text":"and all of this is ignoring encryption via security","ts":"1469451942.000086"},{"type":"message","user":"U0NCW1DPX","text":"if I have to compress data, I will not enable the security.","ts":"1469451949.000087"},{"type":"message","user":"U0XR6J961","text":"why?","ts":"1469451967.000088"},{"type":"message","user":"U0NCW1DPX","text":"just thinking it will effect the performance (compress data + encrypt data)","edited":{"user":"U0NCW1DPX","ts":"1469452184.000000"},"ts":"1469452048.000089"},{"type":"message","user":"U0NCW1DPX","text":"how big the env you have tried?","ts":"1469452096.000090"},{"type":"message","user":"U0XR6J961","text":"i haven't tried much","ts":"1469452165.000091"},{"type":"message","user":"U0NCW1DPX","text":":sob: ok, looks like we are the early adopters, before we release our product we still have a lot of things to do.","ts":"1469452395.000093"},{"type":"message","user":"U0NCW1DPX","text":"I will try to control the number of peers in our first release.","ts":"1469452571.000094"},{"type":"message","user":"U0XR6J961","text":"well independent of that, i don't think you will get such a high transaction number","ts":"1469452620.000095"},{"type":"message","user":"U0NCW1DPX","text":"I think so. Need consider to handler these transactions before write in ledger.","ts":"1469452698.000096"},{"type":"message","user":"U0XR6J961","text":"why are there so many transactions?","ts":"1469452723.000097"},{"type":"message","user":"U0XR6J961","text":"and why do they all have to go to the ledger?","ts":"1469452732.000098"},{"user":"U0UKTPMG8","text":"<@U0UKTPMG8|jeffgarratt> has joined the channel","type":"message","subtype":"channel_join","ts":"1469583772.000099"},{"user":"U1XMKU015","text":"<@U1XMKU015|adamrichard> has joined the channel","type":"message","subtype":"channel_join","ts":"1470205456.000100"},{"user":"U1NBM7NHH","text":"<@U1NBM7NHH|louisw> has joined the channel","type":"message","subtype":"channel_join","ts":"1470243447.000101"},{"user":"U1HD28HEH","text":"<@U1HD28HEH|hangliu> has joined the channel","type":"message","subtype":"channel_join","ts":"1470279323.000102"},{"user":"U1K0ADU82","text":"<@U1K0ADU82|hsukhwa> has joined the channel","type":"message","subtype":"channel_join","ts":"1470702554.000103"},{"user":"U1F3CQ2HX","text":"<@U1F3CQ2HX|nhrishi> has joined the channel","type":"message","subtype":"channel_join","ts":"1470742656.000104"},{"user":"U1ZT4H8MC","text":"<@U1ZT4H8MC|murali> has joined the channel","type":"message","subtype":"channel_join","ts":"1470797952.000105"},{"user":"U21A1B82D","text":"<@U21A1B82D|yitch> has joined the channel","type":"message","subtype":"channel_join","ts":"1471227232.000106"},{"user":"U0N0GDVJ5","text":"<@U0N0GDVJ5|nick> has joined the channel","type":"message","subtype":"channel_join","ts":"1471554972.000107"},{"user":"U23GLSTS4","text":"<@U23GLSTS4|jlamiel> has joined the channel","type":"message","subtype":"channel_join","ts":"1471854721.000108"},{"user":"U23JFU108","text":"<@U23JFU108|csehd> has joined the channel","type":"message","subtype":"channel_join","ts":"1471869588.000109"},{"user":"U24M29R4G","text":"<@U24M29R4G|nikileshsa> has joined the channel","type":"message","subtype":"channel_join","ts":"1472075921.000110"},{"user":"U1P1ZV6RF","text":"<@U1P1ZV6RF|matanyahu> has joined the channel","type":"message","subtype":"channel_join","ts":"1472158545.000111"},{"user":"U1CPB11D0","text":"<@U1CPB11D0|dianfu> has joined the channel","type":"message","subtype":"channel_join","ts":"1472175961.000112"},{"user":"U1S0JCAN4","text":"<@U1S0JCAN4|kaustubhoak> has joined the channel","type":"message","subtype":"channel_join","ts":"1472193790.000113"},{"user":"U1W177934","text":"<@U1W177934|vladimir> has joined the channel","type":"message","subtype":"channel_join","ts":"1472904162.000002"},{"user":"U0NK7T8SH","text":"<@U0NK7T8SH|bryan-huang> has joined the channel","type":"message","subtype":"channel_join","ts":"1473159271.000002"},{"user":"U29TSCRQU","text":"<@U29TSCRQU|a.klenik> has joined the channel","type":"message","subtype":"channel_join","ts":"1473415666.000003"},{"user":"U13Q594J2","text":"<@U13Q594J2|ratnakar> has joined the channel","type":"message","subtype":"channel_join","ts":"1473901350.000004"},{"user":"U2BLUB4Q0","text":"<@U2BLUB4Q0|rmlinden> has joined the channel","type":"message","subtype":"channel_join","ts":"1473956731.000005"},{"type":"message","user":"U1P1ZV6RF","text":"what is the current optimal number of peers that can be running in a network without impacting pbft-based consensus performance?","ts":"1474580335.000006"},{"type":"message","user":"U1P1ZV6RF","text":"in Vukolic's paper \"The Quest for Scalable Blockchain Fabric: Proof-of-Work vs. BFT Replication\" it is claimed that &gt;=20 nodes is optimal for BFT but this is not HL-specific.","ts":"1474580352.000007"},{"type":"message","user":"U0Y14MWA2","text":"Peek (write) throughput always drops with number of replicas so you'd need to specify what you mean by \"optimal\" number","ts":"1474584673.000008"},{"type":"message","user":"U1P1ZV6RF","text":"optimal would mean something around hundreds of txs\/sec","ts":"1474586871.000009"},{"type":"message","user":"U1P1ZV6RF","text":"I am aware of the fact that current version was tested with 4 nodes and it resulted with 240 txs\/sec","edited":{"user":"U1P1ZV6RF","ts":"1474586988.000000"},"ts":"1474586909.000010"},{"type":"message","user":"U12452RAP","text":"<@U1P1ZV6RF>: where is the paper","ts":"1474592136.000012"},{"type":"message","user":"U1P1ZV6RF","text":"<https:\/\/www.google.pl\/url?q=http:\/\/vukolic.com\/iNetSec_2015.pdf&amp;sa=U&amp;ved=0ahUKEwj72c3K36TPAhWBkywKHTSMBnUQFggLMAA&amp;sig2=BoG8U-04wF_kw-3ESGJb0Q&amp;usg=AFQjCNHXdg55Z72wrqEeAjaAhfcsudauGQ>","ts":"1474608223.000013"},{"user":"U0N4P17ND","text":"<@U0N4P17ND|oiakovlev> has joined the channel","type":"message","subtype":"channel_join","ts":"1474629536.000014"},{"type":"message","user":"U0Y14MWA2","text":"<@U1P1ZV6RF> - we have some scalability (peak throughput vs. number of nodes) measurements in-progress on state-machine replication protocols (will post once ready)","ts":"1474631373.000015"},{"type":"message","user":"U1P1ZV6RF","text":"<@U0Y14MWA2> : thanks. BTW, I really liked your paper. It's very layman-friendly.","ts":"1474637646.000016"},{"type":"message","user":"U0Y14MWA2","text":"thanks - it was written that way on purpose (for the same reason, some may say it is handwavy...)","ts":"1474637973.000017"},{"type":"message","user":"U1P1ZV6RF","text":"which papers would you recommend that are closest to describe (P)BFT as present\/planned in Hyperledger Fabric? I went through Liskov\/Castro but it applies to a PoC used for consensus-driven NFS and obviously was not envisaging Blockchain-related application.","ts":"1474638446.000018"},{"type":"message","user":"U0Y14MWA2","text":"v0.5 and v0.6 PBFT is a superset of Castro\/Liskov TOCS'02","ts":"1474638613.000019"},{"type":"message","user":"U0Y14MWA2","text":"(except for the diff in signatures in view change which is a-la OSDI'99)","ts":"1474638633.000020"},{"type":"message","user":"U0Y14MWA2","text":"but now what we are doing (led by <@U0XR6J961>) is effectively a new protocol","ts":"1474638658.000021"},{"type":"message","user":"U0Y14MWA2","text":"inspired by PBFT - let's say","ts":"1474638664.000022"},{"type":"message","user":"U1P1ZV6RF","text":"is it \"Raft\" that you are talking about?","ts":"1474640080.000023"},{"type":"message","user":"U0Y14MWA2","text":"no - raft is crash tolerant protocol","ts":"1474640119.000024"},{"type":"message","user":"U0Y14MWA2","text":"what we are doing now is simplifying pbft slightly on one hand - but hardening it where necessary","ts":"1474640165.000025"},{"type":"message","user":"U0Y14MWA2","text":"simplifcation involves, e.g., removal of watermarks","ts":"1474640193.000026"},{"type":"message","user":"U1P1ZV6RF","text":"ok, thanks","ts":"1474640303.000027"},{"user":"U2J0R1VCY","text":"<@U2J0R1VCY|fredericdgrv> has joined the channel","type":"message","subtype":"channel_join","ts":"1475243925.000028"},{"user":"U2M6CU41G","text":"<@U2M6CU41G|seshadrs> has joined the channel","type":"message","subtype":"channel_join","ts":"1476025456.000029"},{"user":"U1WAADD4N","text":"<@U1WAADD4N|akihikot> has joined the channel","type":"message","subtype":"channel_join","ts":"1476166653.000030"},{"user":"U2FMXLFUJ","text":"<@U2FMXLFUJ|lakshanap> has joined the channel","type":"message","subtype":"channel_join","ts":"1476293564.000031"},{"user":"U2MCH9EEB","text":"<@U2MCH9EEB|crazybit> has joined the channel","type":"message","subtype":"channel_join","ts":"1476356955.000032"},{"user":"U2NNLN56V","text":"<@U2NNLN56V|conghonglei> has joined the channel","type":"message","subtype":"channel_join","ts":"1476667823.000033"},{"user":"U0N1FDZK2","text":"<@U0N1FDZK2|harsh> has joined the channel","type":"message","subtype":"channel_join","ts":"1476984158.000034"},{"user":"U2SE05657","text":"<@U2SE05657|mike_wall> has joined the channel","type":"message","subtype":"channel_join","ts":"1477653982.000035"},{"type":"message","user":"U2SE05657","text":"Hello! I can't see older messages, but really interesting in your progress in development of perfomance-benchmark. Where can I see the results?","ts":"1477654717.000036"},{"user":"U2Q43TYJH","text":"<@U2Q43TYJH|yohei> has joined the channel","type":"message","subtype":"channel_join","ts":"1477893593.000037"},{"user":"U2WE741EC","text":"<@U2WE741EC|cesarlb> has joined the channel","type":"message","subtype":"channel_join","ts":"1477938759.000038"},{"user":"U0XQ35CDD","text":"<@U0XQ35CDD|kostas> has left the channel","type":"message","subtype":"channel_leave","ts":"1478044857.000039"},{"user":"U2YB2R2R1","text":"<@U2YB2R2R1|ptippett> has joined the channel","type":"message","subtype":"channel_join","ts":"1478274333.000040"},{"user":"U0XPR4NP4","text":"<@U0XPR4NP4|jyellick> has left the channel","type":"message","subtype":"channel_leave","ts":"1478280926.000041"},{"user":"U1D89DP47","text":"<@U1D89DP47|subzer0> has joined the channel","type":"message","subtype":"channel_join","ts":"1478981928.000042"},{"user":"U1S0JCAN4","text":"<@U1S0JCAN4|kaustubhoak> has left the channel","type":"message","subtype":"channel_leave","ts":"1479476417.000043"},{"user":"U34KG5R0U","text":"<@U34KG5R0U|marcclaes> has joined the channel","type":"message","subtype":"channel_join","ts":"1479494198.000044"},{"user":"U1F1CU61Y","text":"<@U1F1CU61Y|ankitkamra> has joined the channel","type":"message","subtype":"channel_join","ts":"1479708035.000045"},{"user":"U37P9822X","text":"<@U37P9822X|mwagner> has joined the channel","type":"message","subtype":"channel_join","ts":"1480357232.000046"},{"user":"U365KFA2Y","text":"<@U365KFA2Y|rixon> has joined the channel","type":"message","subtype":"channel_join","ts":"1480387827.000047"},{"user":"U327VGGF9","text":"<@U327VGGF9|yuwei> has joined the channel","type":"message","subtype":"channel_join","ts":"1480905039.000002"},{"user":"U3EGXRAJG","text":"<@U3EGXRAJG|cdutra> has joined the channel","type":"message","subtype":"channel_join","ts":"1481681209.000003"},{"user":"U3HTT7Y9W","text":"<@U3HTT7Y9W|akira> has joined the channel","type":"message","subtype":"channel_join","ts":"1482622487.000004"},{"user":"U3BH74NH0","text":"<@U3BH74NH0|passkit> has joined the channel","type":"message","subtype":"channel_join","ts":"1482896201.000005"},{"user":"U3FLC1GS1","text":"<@U3FLC1GS1|robertock> has joined the channel","type":"message","subtype":"channel_join","ts":"1483363055.000006"},{"user":"U0Z41KY5V","text":"<@U0Z41KY5V|baohua> has left the channel","type":"message","subtype":"channel_leave","ts":"1483659734.000007"},{"user":"U31TA64TT","text":"<@U31TA64TT|newdev2524> has joined the channel","type":"message","subtype":"channel_join","ts":"1483693147.000008"},{"user":"U3PSRK4A1","text":"<@U3PSRK4A1|test_2020> has joined the channel","type":"message","subtype":"channel_join","ts":"1484086172.000009"},{"type":"message","user":"U0PV6MUD6","text":"Has anyone done some performance testing of Fabric recently?","ts":"1484261732.000010","reactions":[{"name":"+1","users":["U3EGXRAJG"],"count":1}]},{"type":"message","user":"U0ULK2JPP","text":"<@U0PV6MUD6> don\u2019t think so \u2026 however recently the chaincode framework was worked to take concurrent invokes. A \u201cccchecker\u201d tool is in examples for testing","edited":{"user":"U0ULK2JPP","ts":"1484263198.000000"},"ts":"1484262164.000011"},{"type":"message","user":"U0ULK2JPP","text":"it can also be used to drive concurrent end-to-end transactions","ts":"1484262190.000012"},{"user":"U1AE6AUMP","text":"<@U1AE6AUMP|joost_zeinstra> has joined the channel","type":"message","subtype":"channel_join","ts":"1484309173.000014"},{"user":"U3S8HRGLV","text":"<@U3S8HRGLV|marcusvcs> has joined the channel","type":"message","subtype":"channel_join","ts":"1484593847.000015"},{"type":"message","user":"U0KM61BCP","text":"<@U0PV6MUD6> coming soon to CI","ts":"1484686951.000016"},{"type":"message","user":"U0KM61BCP","text":"we are working on setting up function, performance, scale and chaotic testing passes that we will run periodically (probably daily, possibly more frequently)","edited":{"user":"U0KM61BCP","ts":"1484687018.000000"},"ts":"1484686998.000017"},{"type":"message","user":"U0PV6MUD6","text":"Okay great! Thanks Chris","ts":"1484687029.000019"},{"user":"U3TT7SN4E","text":"<@U3TT7SN4E|handy> has joined the channel","type":"message","subtype":"channel_join","ts":"1484760183.000020"},{"type":"message","user":"U3PSRK4A1","text":"Can you give more details on performance and scalability tests that you want to perform","ts":"1484774146.000021","reactions":[{"name":"+1","users":["U1HR1RWMR"],"count":1}]},{"user":"U1U7BR1KP","text":"<@U1U7BR1KP|ray> has left the channel","type":"message","subtype":"channel_leave","ts":"1484792113.000022"},{"user":"U3PRALJBS","text":"<@U3PRALJBS|suporn> has joined the channel","type":"message","subtype":"channel_join","ts":"1484815221.000023"},{"type":"message","user":"U0KM61BCP","text":"<@U3PSRK4A1> <@U11HTMW0H> can you please point to our plans?","ts":"1484912345.000024"},{"user":"U3ZBYC8T1","text":"<@U3ZBYC8T1|eragnoli> has joined the channel","type":"message","subtype":"channel_join","ts":"1485853364.000025"},{"user":"U2ZC7UL74","text":"<@U2ZC7UL74|leoni> has joined the channel","type":"message","subtype":"channel_join","ts":"1485947342.000026"},{"user":"U3WM9K85R","text":"<@U3WM9K85R|mbaizan> has joined the channel","type":"message","subtype":"channel_join","ts":"1486021472.000027"},{"user":"U1FBDMBMG","text":"<@U1FBDMBMG|ryokawawork> has joined the channel","type":"message","subtype":"channel_join","ts":"1486033949.000028"},{"user":"U0UHG4VP1","text":"<@U0UHG4VP1|ry> has joined the channel","type":"message","subtype":"channel_join","ts":"1486498044.000029"},{"user":"U0UHG4VP1","members":["U0J5URUJU","U0KM61BCP","U0KPFAZNF","U0MSG4RL7","U0N0GDVJ5","U0N1D1UAE","U0N1FDZK2","U0N1K6Z0X","U0N4P17ND","U0NCW1DPX","U0NK7T8SH","U0P75RFT4","U0PKMSYKG","U0PV6MUD6","U0U2AJURZ","U0UGH3X7X","U0UHG4VP1","U0UKTPMG8","U0ULK2JPP","U0V2F6PU4","U0XR6J961","U0XRC0KLH","U0XV1HDL3","U0Y14MWA2","U0YM41HA5","U0Z541B3P","U0ZJZBJLF","U0ZMB7ZEJ","U0ZR63HLK","U10Q62R8X","U10U36Y4F","U10UX43K6","U1115UL9W","U117F4B6D","U11BP64LD","U11NUTP4L","U12452RAP","U1296EA0M","U12BZTSM8","U137A6LBE","U139XHJCB","U13DAL5V5","U13JUH485","U13Q594J2","U142E5N0P","U14KBK932","U14NC480K","U163J7MRT","U16FB85U6","U16NDNH08","U173QDB0W","U17HK4VQR","U1802P5D3","U18P24857","U196VQF1N","U1A5P979S","U1AE6AUMP","U1AU8DRQR","U1CK6522F","U1CPB11D0","U1D89DP47","U1DFU0M32","U1E795PLG","U1EEGQARJ","U1F1CU61Y","U1F3CQ2HX","U1F9YEMGW","U1FBDMBMG","U1GLPP8QN","U1GN670VD","U1GNP6E7N","U1HD28HEH","U1HFNJB50","U1HR1RWMR","U1JB7QCBD","U1JJ64P53","U1K0ADU82","U1NBM7NHH","U1P1ZV6RF","U1RJ0M1EC","U1S54EHL7","U1SDX7EQZ","U1W177934","U1WAADD4N","U1XMKU015","U1ZT4H8MC","U21A1B82D","U23GLSTS4","U23JFU108","U24M29R4G","U29TSCRQU","U2BLUB4Q0","U2FMXLFUJ","U2J0R1VCY","U2M6CU41G","U2MCH9EEB","U2NNLN56V","U2Q43TYJH","U2SE05657","U2WE741EC","U2YB2R2R1","U2ZC7UL74","U31TA64TT","U327VGGF9","U34KG5R0U","U365KFA2Y","U37P9822X","U3BH74NH0","U3EGXRAJG","U3FLC1GS1","U3HTT7Y9W","U3PRALJBS","U3PSRK4A1","U3S8HRGLV","U3TT7SN4E","U3WM9K85R","U3ZBYC8T1"],"text":"<@U0UHG4VP1|ry> archived the channel (w\/ 117 members)","type":"message","subtype":"channel_archive","ts":"1486498049.000030"}]